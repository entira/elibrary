Cleaned PYPDF2 extraction from: LangChain and LlamaIndex Projects Lab Book_ Hooking Large -- Mark Watson -- 2024 -- Leanpub -- 72798ac862a4a0b5fa655a0ac818181b -- Anna’s Archive.pdf
============================================================

LangChain
and LlamaIndex Projects Lab Book: Hooking Large Language Models Up to
the Real World Using GPT-4, ChatGPT, and Hugging Face Models in Applications.
MarkWatson Thisbookisforsaleat http://leanpub.com/langchain Thisversionwaspublishedon2024-02-01
This
isaLeanpubbook. LeanpubempowersauthorsandpublisherswiththeLeanPublishing
process.LeanPublishing istheactofpublishinganin-progressebookusinglightweighttoolsand
manyiterationstogetreaderfeedback,pivotuntilyouhavetherightbookandbuildtractiononce
youdo.
This
workislicensedundera CreativeCommonsAttribution-NonCommercial-ShareAlike4.0
InternationalLicense Also ByMark Watson SafeForHumansAI
DasLangChainundLlamaIndexProjectsLabBuch: LargeLanguageModelsfürdieEchteWelt PracticalPythonArtificialIntelligenceProgramming PracticalArtificialIntelligenceDevelopmentWithRacket PracticalArtificialIntelligenceProgrammingWithClojure ArtificialIntelligenceUsingSwift ALispProgrammerLivinginPython-Land: TheHyProgrammingLanguage HaskellTutorialandCookbook LovingCommonLisp,ortheSavvyProgrammer’sSecretWeapon PracticalArtificialIntelligenceProgrammingWithJava Contents Pr
eface. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
AbouttheAuthor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
BookCover . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
RequirementsforRunningandModifyingBookExamples . . . . . . . . . . . . . . . . . . . . 3
IssuesandWorkaroundsforUsingtheMaterialinthisBook . . . . . . . . . . . . . . . . . . . 4
Large Language Model Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
BigTechBusinessesvs. SmallStartupsUsingLargeLanguageModels . . . . . . . . . . . . . 5
Getting Started With LangChain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
InstallingNecessaryPackages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
CreatingaNewLangChainProject . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
BasicUsageandExamples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
CreatingEmbeddings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
UsingLangChainVectorStorestoQueryDocuments. . . . . . . . . . . . . . . . . . . . . . . . 12
ExampleUsingLangChainIntegrations: UsingServerAPIsforGoogleSearch . . . . . . . . 14
LangChainOverviewWrapUp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
Overview of LlamaIndex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
UsingLlamaIndextoSearchLocalDocumentsUsingGPT-3 . . . . . . . . . . . . . . . . . . . 16
UsingLlamaIndexforQuestionAnsweringfromaListofWebSites . . . . . . . . . . . . . . 18
LlamaIndex/GPT-IndexCaseStudyWrapUp. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
Retrieval Augmented Generation (RAG) Applications . . . . . . . . . . . . . . . . . . . . . . . 21
Using Google’s Knowledge Graph APIs With LangChain . . . . . . . . . . . . . . . . . . . . . 22
SettingUpToAccessGoogleKnowledgeGraphAPIs . . . . . . . . . . . . . . . . . . . . . . . 22
Using DBPedia and WikiData as Knowledge Sources . . . . . . . . . . . . . . . . . . . . . . . . 27
UsingDBPediaasaDataSource . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
UsingWikidataasaDataSource . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
Using LLMs To Organize Information in Our Google Drives . . . . . . . . . . . . . . . . . . . 36
SettingUpRequirements. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
WriteUtilityToFetchAllTextFilesFromTopLevelGoogleDriveFolder . . . . . . . . . . . 38
Generate VectorIndicesforFilesinSpecificGoogleDriveDirectories . . . . . . . . . . . . . 40
GoogleDriveExampleWrapUp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
Using Zapier Integrations With GMail and Google Calendar . . . . . . . . . . . . . . . . . . . 42
SetUpDevelopmentEnvironment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
SendingaTestGMail . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
GoogleCalendarIntegrationExample . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
Natural Language SQLite Database Queries With LangChain . . . . . . . . . . . . . . . . . . 46
NaturalLanguageDatabaseQueryWrapUp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
Examples Using Hugging Face Open Source Models . . . . . . . . . . . . . . . . . . . . . . . . 49
UsingLangChainasaWrapperforHuggingFacePredictionModelAPIs . . . . . . . . . . . 49
CreatingaCustomLlamaIndexHuggingFaceLLMWrapperClassThatRunsonYourLaptop 50
Running Local LLMs Using Llama.cpp and LangChain . . . . . . . . . . . . . . . . . . . . . . . 54
InstallingLlama.cppwithaLlama2-13b-orcaModel . . . . . . . . . . . . . . . . . . . . . . . . 54
PythonExample . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
Running Local LLMs Using Ollama . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
SimpleUseofalocalMistralModelUsingLangChain . . . . . . . . . . . . . . . . . . . . . . . 57
Minimal Example Using Ollama with the Mistral Open Model for Retrieval Augmented QueriesAgainstLocalDocuments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
Wrap Up for Running Local LLMs Using Ollama . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
Using Large Language Models to Write Recipes . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
PreparingRecipeData. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
APredictionModelUsingtheOpenAItext-embedding-3-largeModel . . . . . . . . . . . . . 63
CookingRecipeGenerationWrapUp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
LangChain Agents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
OverviewofLangChainTools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
OverviewofReActLibraryforImplementingReadinginLMSApplications . . . . . . . . . . 68
LangChainAgentToolExampleUsingDBPediaSPARQLQueries . . . . . . . . . . . . . . . . 69
LangChainAgentToolsWrapUp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
More Useful Libraries for Working with Unstructured Text Data . . . . . . . . . . . . . . . . 76
EmbedChainWrapperforLangChainSimplifiesApplicationDevelopment . . . . . . . . . . 76
KorLibrary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
Book Wrap Up . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
Pr
eface I have been working in the field of artificial intelligence since 1982 and withoutadoubt Large LanguageModels(LLMs)likeGPT-4representthegreatestadvanceinpracticalAItechnologythat I have experienced. Infrastructure projects like LangChain and LlamaIndex make it simpler to use LLMs and provide some level of abstraction to facilitate switching between LLMs. This book will
use theLangChain1andLlamaIndex2projects along with the OpenAI GPT-3.5, GPT-4, ChatGPT
APIs,andlocalmodelsrunonyourcomputertosolveaseriesofinterestingproblems.
AsIwritethisneweditioninJanuary2024,ImostlyrunlocalLLMsbutIstilluseOpenAIAPIs,as
wellaswellasAPIsfromAnthropicfortheClaude2model.
Harrison Chase started the LangChain project in October 2022 and as I wrote the first book in February 2023 the GitHub repository for LangChain 171 contributors and as I write this new
edition LangChain has 2100+ contributors on GitHub. Jerry Liu started the GPT Index project
(recently renamed to LlamaIndex) at the end of 2022 and the GitHub Repository for LlamaIndex
https://github.com/jerryjliu/gpt_index3currentlyhas54contributors.
The GitHub repository for examples in this book is https://github.com/mark-watson/langchain-
book-examples.git . Please note that I usually update the code in the examples repository fairly
frequentlyforlibraryversionupdates,etc.
While the documentation and examples online for LangChain and LlamaIndex are excellent,
I am still motivated to write this book to solve interesting problems that I like to work on
involvinginformationretrieval,naturallanguageprocessing(NLP),dialogagents,andthesemantic
web/linkeddatafields. Ihopethatyou,dearreader,willbedelightedwiththeseexamplesandthat
atleastsomeofthemwillinspireyourfutureprojects.
About the Author Ihavewrittenover20books,Ihaveover50USpatents,andIhaveworkedatinterestingcompanies
like Google, Capital One, SAIC, Mind AI, and others. You can find links for reading most of my
recent books free on my web site https://markwatson.com . If I had to summarize my career the
short take would be that I have hadalot of fun and enjoyed my work. I hope that what you learn
herewillbebothenjoyableandhelpyouinyourwork.
If you would like to support my work please consider purchasing my books on Leanpub4and star
1https://github.com/langchain-
ai/langchain
2https://github.com/run-llama/llama_index
3https://github.com/run-llama/llama_index
4https://leanpub.com/u/markwatson Preface 2
mygitrepositoriesthatyoufindusefulon GitHub5. Youcanalsointeractwithmeonsocialmedia
onMastodon6andTwitter7. Iamalsoavailableasaconsultant: https://markwatson.com .
Book Cover IliveinSedona,Arizona. ItookthebookcoverphotoinJanuary2023fromthestreetthatIliveon.
Acknowledgements ThispictureshowsmeandmywifeCarolwhohelpsmewithbookproductionandediting.
5https://github.com/mark-
watson?tab=repositories&q=&type=public
6https://mastodon.social/@mark_watson
7https://twitter.com/mark_l_watson Preface 3
Figur
e 1. Mark and Carol Watson Iwouldalsoliketothankthefollowingreaderswhoreportederrorsortyposinthisbook: Armando Flores,PeterSolimine,andDavidRupp.
Requirements for Running and Modifying Book Examples Ishowfullsourcecodeandafairamountofexampleoutputforeachbookexamplesoifyoudon’t
wanttogetaccesstosomeofthefollowingAPIsthenyoucanstillreadalonginthebook.
To use OpenAI’s GPT-3 and ChatGPT models you will need to sign up for an API key (free tier is Preface 4
OK) athttps://openai.com/api/ and set the environment variable OPENAI_API_KEY to your key
value.
YouwillneedtogetanAPIkeyforexamplesusing Google’s Knowledge Graph APIs .
Reference: GoogleKnowledgeGraphAPIs8.
The example programs using Google’s Knowledge Graph APIs assume that you have the file
~/.google_api_key inyourhomedirectorythatcontainsyourkeyfrom https://console.cloud.google.
com/apis.
You will need to install SerpApi for examples integrating web search . Please reference: PyPi
projectpage9.
Youcansignupforafreenon-commercial100searches/monthaccountwithanemailaddressand
phonenumberat https://serpapi.com/users/welcome .
Youwillalsoneed Zapier10accountfortheGMailandGoogleCalendarexamples.
After reading though this book, you can review the website LangChainHub11which contains
prompts,chainsandagentsthatareusefulforbuildingLLMapplications.
Issues and Workarounds for Using the Material in this Book The libraries that I use in this book are frequently updated and sometimes the documentation or
code links change, invalidating links in this book. I will try to keep everything up to date. Please
reportbrokenlinkstome.
Insomecasesyouwillneedtousespecificversionsorlibrariesforsomeofthecodeexamples.
BecausethePythoncodelistingsusecolorizedtextyoumayfindthatcopyingcodefromthiseBook
maydropspacecharacters. AllofthecodelistingsareintheGitHubrepositoryforthisbooksoyou
shouldclonetherepositorytoexperimentwiththeexamplecode.
8https://cloud.google.com/enterprise-
knowledge-graph/docs/search-api
9https://pypi.org/project/google-search-results/
10https://zapier.com
11https://github.com/hwchase17/langchain-hub Lar
ge Language Model Overview Large language models1areasubset of artificial intelligence that use deep learning and neural
networks to process natural language. Transformers2areatype of neural network architecture
that can learn context in sequential data using self-attention mechanisms. They were introduced
in 2017 byateam at Google Brain and have become popular for LLM research. Some examples of
transformer-based3LLMsare BERT,GPT-3,T5andMegatron-LM4.
Themainpointswewilldiscussinthisbookare:
• LLMs are deep learning algorithms that can understand and generate natural language based
onmassivedatasets.
• LLMsusetechniquessuchasself-attention,masking,andfine-tuningtolearncomplexpatterns
and relationships in language. LLMs can understand and generate natural language because
they use transformer models, which areatype of neural network that can process sequential
datasuchastextusingattentionmechanisms. Attentionmechanismsallowthemodeltofocus
onrelevantpartsoftheinputandoutputsequenceswhileignoringirrelevantones.
• LLMscanperformvariousnaturallanguageprocessing(NLP)andnaturallanguagegeneration
(NLG) tasks, such as summarization, translation, prediction, classification, and question
answering.
• Even though LLMs were initially developed for NLP applications, LLMs have also shown
potential in other domains such as computer vision and computational biology by leveraging
theirgeneralizableknowledgeandtransferlearningabilities.
BERT models5are one of the first types of transformer models that were widely used. BERT was
developed by Google AI Language in 2018. BERT models areafamily of masked language models
that use transformer architecture to learn bidirectional representations of natural language. BERT
modelscanunderstandthemeaningofambiguouswordsbyusingthesurroundingtextascontext.
The “magic trick” here is that training data comes almost free because in masking models, you
programatically chose random words, replace them withamissing word token, and the model is
trainedtopredictthemissingwords. Thisprocessisrepeatedwithmassiveamountsoftrainingdata
fromtheweb,books,etc.
Here are some “papers with code” links for BERT (links are for code, paper links in the code
repositories):
•https://github.com/allenai/scibert
•https://github.com/google-research/bert
1https://blogs.nvidia.com/blog/2022/10/10/llms-
ai-horizon/
2https://www.linkedin.com/pulse/chatgpt-tip-iceberg-paul-golding
3https://factored.ai/transformer-based-language-models/
4https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)
5https://en.wikipedia.org/wiki/BERT_(Language_model)
LargeLanguageModelOverview 6
Big Tech Businesses vs. Small Startups Using Large Language Models Both Microsoft and Google play both sides of this business game: they want to sell cloud LLM
services to developers and small startup companies and they would also like to achieve lock-in for
theirconsumerserviceslikeOffice365,GoogleDocsandSheets,etc.
Microsoft has been integrating AI technology into workplace emails, slideshows, and spreadsheets
as part of its ongoing partnership with OpenAI, the company behind ChatGPT. Microsoft’s Azure OpenAIserviceoffersapowerfultooltoenabletheseoutcomeswhenleveragedwiththeirdatalake
ofmorethantwobillionmetadataandtransactionalelements.
AsIwritethis,GooglehasjustopenedapublicwaitlistfortheirBardAI/chatsearchservice. Ihave
used various Google APIs for years in code I write. I have no favorites in the battle between tech
giants,ratherIammostlyinterestedinwhattheybuildthatIcanuseinmyownprojects.
HuggingFace,whichmakesAIproductsandhoststhosedevelopedbyothercompanies,isworking
on open-source rivals to ChatGPT and will use AWS6for that as well. Cohere AI, Anthropic,
Hugging Face, and Stability AI are some of the startups that are using OpenAI and Hugging Face APIsfortheirproducts. AsIwritethischapter,IviewHuggingFaceasagreatsourceofspecialized
models. IlovethatHuggingFacemodelscanberunviatheirAPIsandalsoself-hostedonourown
servers and sometimes even on our laptops. Hugging Face isafantastic resource and even though I use their models much less frequently in this book than OpenAI APIs, you should embrace the
hosting and open source flexibility of Hugging Face. Here I use OpenAI APIs because I want you
togetsetupandcreatingyourownprojectsquickly.
Dearreader,Ididn’twritethisbookfordevelopersworkingatestablishedAIcompanies(although Ihopesuchpeoplefindthematerialhereuseful!). Iwrotethisbookforsmalldeveloperswhowant
to scratch their own itch by writing tools that save them time. I also wrote this book hoping that
itwouldhelpdevelopersbuildcapabilitiesintotheprogramstheydesignandwritethatrivalwhat
thebigtechcompaniesaredoing.
6https://iblnews.org/aws-
partners-with-hugging-face-an-ai-startup-rival-to-chatgpt-working-on-open-source-models/
Getting Started With LangChain LangChain1isaframework for building applications with large language models (LLMs) through
chaining different components together. Some of the applications of LangChain are chatbots,
generative question-answering, summarization, data-augmented generation and more. LangChain
can save time in building chatbots and other systems by providingastandard interface for chains,
agents and memory, as well as integrations with other tools and end-to-end examples. We refer
to “chains” as sequences of calls (to an LLMs andadifferent program utilities, cloud services, etc.)
that go beyond just one LLM API call. LangChain providesastandard interface for chains, many
integrationswithothertools, andend-to-endchainsforcommonapplications. Oftenyouwillfind
existingchainsalreadywrittenthatmeettherequirementsforyourapplications.
For example, one can createachain that takes user input, formats it using a PromptTemplate, and
thenpassestheformattedresponsetoaLargeLanguageModel(LLM)forprocessing.
While LLMs are very general in nature which means that while they can perform many tasks
effectively, they often can not directly provide specific answers to questions or tasks that require
deepdomainknowledgeorexpertise. LangChainprovidesastandardinterfaceforagents,alibrary
ofagentstochoosefrom,andexamplesofend-to-endagents.
LangChainMemoryistheconceptofpersistingstatebetweencallsofachainoragent. LangChain
providesastandard interface for memory, a collection of memory implementations, and examples
ofchains/agentsthatusememory². LangChainprovidesalargecollectionofcommonutilstousein
yourapplication. ChainsgobeyondjustasingleLLMcall,andaresequencesofcalls(whethertoan LLMoradifferentutility). LangChainprovidesastandardinterfaceforchains,lotsofintegrations
withothertools,andend-to-endchainsforcommonapplications.
LangChaincanbeintegratedwithoneormoremodelproviders, datastores, APIs, etc. LangChain
can be used for in-depth question-and-answer chat sessions, API interaction, or action-taking.
LangChain can be integrated with Zapier’s platform throughanatural language API interface (we
haveanentirechapterdedicatedtoZapierintegrations).
Installing Necessary Packages For the purposes of examples in this book, you might want to createanew Anaconda or other Pythonenvironmentandinstall:
1https://api.python.langchain.com/en/stable/langchain_api_reference.html GettingStartedWithLangChain 8
1pip install -U langchain llama_index openai langchain-openai
2pip install -U langchain-community langchainhub
3pip install -U kor pydrive pandas rdflib
4pip install -U google-search-results SPARQLWrapper Fortherestofthischapterwewillusethesubdirectory langchain_getting_started andinthenext
chapteruse llama-index_case_study intheGitHubrepositoryforthisbook.
Creating a New LangChain Project Simple LangChain projects are often justavery short Python script file. As you read this book,
when any example looks interesting or useful, I suggest copying the requirements.txt and Python
sourcefilestoanewdirectoryandmakingyourownGitHubprivaterepositorytoworkin. Please
maketheexamplesinthisbook“yourcode,”thatis,freelyreuseanycodeorideasyoufindhere.
Basic Usage and Examples While I try to make the material in this book independent, something you can enjoy with no
externalreferences,youshouldalsotakeadvantageofthehighquality LangchainQuickstartGuide
documentation2and the individual detailed guides for prompts, chat, document loading, indexes,
etc.
As we work through some examples please keep in mind what it is like to use the ChatGPT web
application: youentertextandgetresponses. ThewayyoupromptChatGPTisobviouslyimportant
if you want to get useful responses. In code examples we automate and formalize this manual
process.
You need to choose a LLM to use. We will usually choose the GPT-4 API from OpenAI because it
isgeneralpurposebutismoreexpensivethattheolderGPT-3.5APIs. Youwillneedto signup3for
anAPIkeyandsetitasanenvironmentvariable:
1export OPENAI_API_KEY ="YOUR KEY GOES HERE"
Boththelibraries openaiandlangchain willlookforthisenvironmentvariableanduseit. Wewill
lookatafewsimpleexamplesinaPythonREPL.WewillstartbyjustusingOpenAI’stextprediction API:
2https://python.langchain.com/docs/get_started/quickstart
3https://platform.openai.com/account/api-
keys GettingStartedWithLangChain 9
1$python
2>>> from langchain_openai import OpenAI
3>>> llm = OpenAI(temperature=0.8)
4>>> s = llm("John got into his new sports car, and he drove it")
5>>> s
6' to work\n\nJohn started up his new sports car and drove it to work. He hadahuge \
7smile on his face as he drove, excited to show off his new car to his colleagues. Th
8e wind blowing through his hair, and the sun on his skin, he feltasense of freedom
9 and joy as he cruised along the road. He arrived at work in no time, feeling refres
10 hed and energized.'
11 >>> s = llm("John got into his new sports car, and he drove it")
12 >>> s
13 " around town\n\nJohn drove his new sports car around town, enjoying the feeling of \
14 the wind in his hair. He stopped to admire the view fromascenic lookout, and then
15 sped off to the mall to do some shopping. On the way home, he tookadetour downaw
16 inding country road, admiring the scenery and enjoying the feel of the car's powerfu
17 l engine. By the time he arrived back home, he hadahuge smile on his face."
Noticehowwhenweranthesameinputtextprompttwicethatweseedifferentresults.Settingthe
temperatureinline3toahighervalueincreasestherandomness.
Ournextexampleisinthesourcefile directions_template.py inthedirectory langchain_getting_-
startedandusesthe PromptTemplate class. A prompttemplate isa reproducibleway togenerateaprompt. It containsatext string (“the template”), that can take inaset of parameters from the
end user and generateaprompt. The prompt template may contain language model instructions,
few-shotexamplestoimprovethemodel’sresponse,orspecificquestionsforthemodeltoanswer.
1from langchain.prompts import PromptTemplate
2from langchain_openai import OpenAI
3llm =OpenAI(temperature =0.9)
4
5def get_directions (thing_to_do):
6 prompt =PromptTemplate(
7 input_variables =["thing_to_do"],
8 template ="How do I {thing_to_do} ?",
9 )
10 prompt_text =prompt .format(thing_to_do =thing_to_do)
11 print(f"\n{prompt_text }:")
12 return llm(prompt_text)
13
14 print(get_directions( "get to the store"))
15 print(get_directions( "hangapicture on the wall"))
GettingStartedWithLangChain 10
YoucouldjustwritePythonstringmanipulationcodetocreateapromptbutusingtheutilityclass PromptTemplate ismorelegibleandworkswithanynumberofpromptinputvariables.
Theoutputis:
1$python directions_template.py
2
3How do I get to the store?:
4
5To get to the store, you will need to useamode of transportation such as walking, \
6driving, biking, or taking public transportation. Depending on the location of the s
7tore, you may need to look up directions or maps to determine the best route to take
8.
9
10 How do I hangapicture on the wall?:
11
12 1. Findastud in the wall, or use two or three wall anchors for heavier pictures.
13 2. Measure and mark the wall where the picture hanger will go.
14 3. Pre-drill the holes and place wall anchors if needed.
15 4. Hammer the picture hanger into the holes.
16 5. Hang the picture on the picture hanger.
Thenextexampleinthefile country_information.py isderivedfromanexampleintheLangChain
documentation. In this example we use PromptTemplate that contains the pattern we would like
theLLMtousewhenreturningaresponse.
1from langchain.prompts import PromptTemplate
2from langchain_openai import OpenAI
3llm =OpenAI(temperature =0.9)
4
5def get_country_information (country_name):
6 print(f"\nProcessing {country_name }:")
7 global prompt
8 if"prompt" not in globals ():
9 print("Creating prompt...")
10 prompt =PromptTemplate(
11 input_variables =["country_name"],
12 template ="""
13 Predict the capital and population ofacountry.
14
15 Country: {country_name}
16 Capital:
17 Population:""",
GettingStartedWithLangChain 11
18 )
19 prompt_text =prompt .format(country_name =country_name)
20 print(prompt_text)
21 return llm(prompt_text)
22
23 print(get_country_information( "Canada"))
24 print(get_country_information( "Germany"))
You can use the ChatGPT web interface to experiment with prompts and when you findapattern
that works well then write a Python script like the last example, but changing the data you supply
inthe PromptTemplate instance.
Theoutputofthelastexampleis:
1 $python country_information.py
2
3Processing Canada:
4Creating prompt...
5
6Predict the capital and population ofacountry.
7
8Country: Canada
9Capital:
10 Population:
11
12
13 Capital: Ottawa
14 Population: 37,058,856 (as of July 2020)
15
16 Processing Germany:
17
18 Predict the capital and population ofacountry.
19
20 Country: Germany
21 Capital:
22 Population:
23
24
25 Capital: Berlin
26 Population: 83,02 million (est. 2019)
GettingStartedWithLangChain 12
Creating Embeddings We will reference the LangChain embeddings documentation4. We can use a Python REPL to see
whattexttovectorspaceembeddingsmightlooklike:
1$python
2Python 3.10.8 (main, Nov 24 2022, 08:08:27) [Clang 14.0.6 ] on darwin
3Type "help", "copyright", "credits" or "license" for more information.
4>>> from langchain_openai import OpenAIEmbeddings
5>>> embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
6>>> text = "Mary has blond hair and John has brown hair. Mary lives in town and John\
7 lives in the country."
8>>> doc_embeddings = embeddings.embed_documents([text])
9>>> doc_embeddings
10 [[0.007727328687906265, 0.0009025644976645708, -0.0033224383369088173, -0.0179449208\
11 0807686, -0.017969949170947075, 0.028506645932793617, -0.013414892368018627, 0.00466
12 76816418766975, -0.0024965214543044567, -0.02662956342101097,
13 ...]]
14 >>> query_embedding = embeddings.embed_query("Does John live in the city?")
15 >>> query_embedding
16 [0.028048301115632057, 0.011499025858938694, -0.00944007933139801, -0.02080961130559\
17 4444, -0.023904507979750633, 0.018750663846731186, -0.01626438833773136, 0.018129095
18 435142517,
19 ...]
20 >>>
Noticethatthe doc_embeddings isalistwhereeachlistelementistheembeddingsforoneinputtext
document. The query_embedding isasingleembedding. Pleasereadtheabovelinkedembedding
documentation.
Wewillusevectorstorestostorecalculatedembeddingsforfutureuse. Inthenextchapterwewill
seeadocumentdatabasesearchexampleusingLangChainandLlama-Index.
Using LangChain Vector Stores to Query Documents Wewillreferencethe LangChainVectorStoresdocumentation5. Youneedtoinstallafewlibraries:
4https://python.langchain.com/en/latest/reference/modules/embeddings.html
5https://python.langchain.com/en/latest/reference/modules/vectorstore.html GettingStartedWithLangChain 13
1pip install chroma
2pip install chromadb
3pip install unstructured pdf2image pytesseract Theexamplescriptis doc_search.py :
1from langchain.text_splitter import CharacterTextSplitter
2from langchain.vectorstores import Chroma
3from langchain.embeddings import OpenAIEmbeddings
4from langchain.document_loaders import DirectoryLoader
5from langchain import VectorDBQA
6from langchain_openai import OpenAI
7
8embeddings =OpenAIEmbeddings(model ="text-embedding-3-large")
9
10 loader =DirectoryLoader( '../data/', glob="**/*.txt")
11 documents =loader .load()
12 text_splitter =CharacterTextSplitter(chunk_size =2500, chunk_overlap=0)
13
14 texts =text_splitter .split_documents(documents)
15
16 docsearch =Chroma .from_documents(texts, embeddings)
17
18 qa=VectorDBQA .from_chain_type(llm =OpenAI(),
19 chain_type ="stuff",
20 vectorstore =docsearch)
21
22 def query(q):
23 print(f"Query: {q}")
24 print(f"Answer: {qa.run(q) }")
25
26 query( "What kinds of equipment are inachemistry laboratory?")
27 query( "What is Austrian School of Economics?")
28 query( "Why do people engage in sports?")
29 query( "What is the effect of body chemistry on exercise?")
TheDirectoryLoader classisusefulforloadingadirectoryfullofinputdocuments. Inthisexample
we specified that we only want to process text files, but the file matching pattern could have also
specifiedPDFfiles,etc.
Theoutputis:
GettingStartedWithLangChain 14
1$python doc_search.py
2Createdachunk of size 1055, which is longer than the specified 1000
3Running Chroma using direct local API.
4Using DuckDB in-memory for database. Data will be transient.
5Query: What kinds of equipment are inachemistry laboratory?
6Answer: A chemistry lab would typically include glassware, such as beakers, flasks,\
7 and test tubes, as well as other equipment such as scales, Bunsen burners, and ther
8mometers.
9Query: What is Austrian School of Economics?
10 Answer: The Austrian School isaschool of economic thought that emphasizes the spo\
11 ntaneous organizing power of the price mechanism. Austrians hold that the complexity
12 of subjective human choices makes mathematical modelling of the evolving market ext
13 remely difficult and advocate a "laissez faire" approach to the economy. Austrian Sc
14 hool economists advocate the strict enforcement of voluntary contractual agreements
15 between economic agents, and hold that commercial transactions should be subject to
16 the smallest possible imposition of forces they consider to be (in particular the sm
17 allest possible amount of government intervention). The Austrian School derives its
18 name from its predominantly Austrian founders and early supporters, including Carl M
19 enger, Eugen von Bohm-Bawerk and Ludwig von Mises.
20 Query: Why do people engage in sports?
21 Answer: People engage in sports for leisure and entertainment, as well as for physi\
22 cal exercise and athleticism.
23 Query: What is the effect of body chemistry on exercise?
24 Answer: Body chemistry can affect the body's response to exercise, as certain hormo\
25 nes and enzymes produced by the body can affect the energy levels and muscle perform
26 ance. Chemicals in the body, such as adenosine triphosphate (ATP) and urea, can affe
27 ct the body's energy production and muscle metabolism during exercise. Additionally,
28 the body's levels of electrolytes, vitamins, and minerals can affect exercise perfo
29 rmance.
30 Exiting: Cleaning up .chroma directory Example Using LangChain Integrations: Using Server APIs for Google Search The example shown here is in the directory from_langchain_docs in the source file search_sim-
ple.py. TherelevantLangChainIntegrationsdocumentationpageis https://python.langchain.com/
docs/integrations/tools/google_serper .
GettingStartedWithLangChain 15
1# make sure SERPER_API_KEY is set in your environment
2
3from langchain_community.utilities import GoogleSerperAPIWrapper
4search_helper =GoogleSerperAPIWrapper()
5
6def search (query):
7 return search_helper .run(query)
8
9print(search( "What is the capital of Arizona?"))
10 #print(search("Sedona Arizona?"))
You will need a Server API key form https://serper.dev . Currently you can getafree key for 2500
APIcalls. Afterthatthepaidtiercurrentlystartsat$50for50KAPIcallsandthesecreditsmustbe
usedwithina6monthperiod.
LangChain Overview Wrap Up We will continue using LangChain for the rest of this book as well as the LlamaIndex library that
weintroduceinthenextchapter.
I cover just the subset of LangChain that I use in my own projects in this book. I urge you to read
the LangChain documentation and to explore public LangChain chains that users have written on Langchain-hub6.
6https://github.com/hwchase17/langchain-
hub Overviewof LlamaIndex ThepopularLlamaIndexprojectusedtobecalledGPT-Indexbuthasbeengeneralizedtoworkwith
moremodelsthatjustGPT-3,forexample usingHuggingFaceembeddings1.
LlamaIndex2isaproject that providesacentral interface to connect your language models with
externaldata. ItwascreatedbyJerryLiuandhisteaminthefallof2022. Itconsistsofasetofdata
structures designedtomakeiteasiertouselargeexternalknowledgebaseswithlanguagemodels3.
Someofitsusesare:
• Queryingstructureddatasuchastablesordatabasesusingnaturallanguage
• Retrievingrelevantfactsorinformationfromlargetextcorpora
• Enhancinglanguagemodelswithdomain-specificknowledge LlamaIndexsupportsavarietyofdocumenttypes,including:
• Text documents are the most common type of document. They can be stored inavariety of
formats,suchas.txt,.doc,and.pdf.
• XMLdocumentsareatypeoftextdocumentthatisusedtostoredatainastructuredformat.
• JSONdocumentsareatypeoftextdocumentthatisusedtostoredatainalightweightformat.
• HTMLdocumentsareatypeoftextdocumentthatisusedtocreatewebpages.
• PDFdocumentsareatypeoftextdocumentthatisusedtostoredocumentsinafixedformat.
LlamaIndexcanalsoindexdatathatisstoredinavarietyofdatabases,including:
• SQLdatabasessuchasMySQL,PostgreSQL,andOracle. NoSQLdatabasessuchasMongoDB,
Cassandra,andCouchDB.
• Solrisapopularopen-sourcesearchenginethatprovideshighperformanceandscalability.
• Elasticsearch is another popular open-source search engine that offersavariety of features,
includingfull-textsearch,geospatialsearch,andmachinelearning.
• ApacheCassandraisaNoSQLdatabasethatcanbeusedtostorelargeamountsofdata.
• MongoDBisanotherNoSQLdatabasethatiseasytouseandscale.
• PostgreSQLisarelationaldatabasethatiswidelyusedinenterpriseapplications.
LlamaIndexisaflexibleframeworkthatcanbeusedtoindexavarietyofdocumenttypesanddata
sources.
WewilllookfirstatashortexamplederivedfromtheLlamaIndexdocumentationandlaterlookat
thepartsoftheLlmaIndexsourcecodethatusesLangChain.
1https://gpt-
index.readthedocs.io/en/latest/how_to/customization/embeddings.html
2https://github.com/jerryjliu/gpt_index/blob/main/docs/index.rst
3https://gpt-index.readthedocs.io/en/latest/index.html OverviewofLlamaIndex 17
Using LlamaIndex to Search Local Documents Using GPT-3
The following example is similar to the last example in the overview chapter on LangChain. In
line8weuseautilitydataloaderfunctionprovidedbyLlamaIndextoreaddocumentsinaninput
directory. Asademonstrationwesavetheindex(consistingofdocumentembeddings)todiskand
reloadit. Thistechniqueisusefulwhenyouhavealargenumberofstaticdocumentssotheindexing
procedure can takeawhile and require many OpenAI API calls. As an example, you might have
many gigabytes of company documentation that doesn’t change often so it makes sense to only
occasionallyrecreatetheindex.
1# make sure you set the following environment variable is set:
2# OPENAI_API_KEY
3
4from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader
5from llama_index import StorageContext, load_index_from_storage
6
7documents =SimpleDirectoryReader( '../data').load_data()
8# index = GPTListIndex(documents) # llama_index < 0.5
9index =GPTVectorStoreIndex .from_documents(documents)
10 engine =index.as_query_engine()
11 print(engine .query( "what are key economic indicators?"))
12
13 # save to disk
14 index.storage_context .persist(persist_dir ='./cache')
15
16 # load from disk
17 storage_context =StorageContext .from_defaults(persist_dir ='./cache')
18 index =load_index_from_storage(storage_context)
19 engine =index.as_query_engine()
20
21 # search foradocument
22 print(engine .query( "effect of body chemistry on exercise?"))
Youmayhavenoticedthatthequerydefinedonline17isthesamequerythatweusedlastchapter.
OverviewofLlamaIndex 18
1$python test_from_docs.py
2
3Key economic indicators are measures of economic activity that are used to assess th\
4e health of an economy. Examples of key economic indicators include gross domestic p
5roduct (GDP), unemployment rate, inflation rate, consumer price index (CPI), balance
6 of trade, and industrial production.
7
8The effect of body chemistry on exercise depends on the type of exercise being perfo\
9rmed. For aerobic exercise, the body needs to be able to produce enough energy to su
10 stain the activity. This requires the body to have adequate levels of oxygen, glucos
11 e, and other nutrients in the bloodstream. For anaerobic exercise, the body needs to
12 be able to produce energy without relying on oxygen. This requires the body to have
13 adequate levels of lactic acid, creatine phosphate, and other energy-producing mole
14 cules. In both cases, the body's chemistry must be balanced in order for the exercis
15 e to be effective.
Using LlamaIndex for Question Answering from a List
of Web Sites Inthisexampleweusethe trafilatura andhtml2text librariestogettextfromawebpagethatwe
willindexandsearch. Theclass TrafilaturaWebReader doestheworkofcreatinglocaldocuments
fromalist of web page URIs and the index class GPTListIndex buildsalocal index for use with OpenAIAPIcallstoimplementsearch.
Thefollowinglistingshowsthefile web_page_QA.py :
1# Derived from the example at:
2# https://github.com/jerryjliu/gpt_index/blob/main/examples/data_connectors/WebPageD\
3emo.ipynb
4
5# pip install llama-index, html2text, trafilatura
6
7from llama_index import GPTListIndex
8from llama_index import TrafilaturaWebReader
9
10 def query_website (url_list, *questions):
11 documents =TrafilaturaWebReader() .load_data(url_list)
12 # index = GPTListIndex(documents) # llama_index < 0.5
13 index =GPTListIndex .from_documents(documents)
14 engine =index.as_query_engine()
15 for question inquestions:
OverviewofLlamaIndex 19
16 print(f"\n== QUESTION: {question }\n")
17 response =engine .query(question)
18 print(f"== RESPONSE: {response }")
19
20 if__name__ =="__main__":
21 url_list =["https://markwatson.com"]
22 query_website(url_list, "How many patents does Mark have?",
23 "How many books has Mark written?")
This example is not efficient because we createanew index for each web page we want to search.
That said, this example (that was derived from an example in the LlamaIndex documentation)
implementsapattern that you can use, for example, to buildareusable index of your company’s
websiteandbuildanend-userwebsearchapp.
Theoutputforthesethreetestquestionsinthelastcodeexampleis:
1 $python web_page_QA.py
2documents:
3[Document(text ='Mark Watson’s Artificial Intelligence Books and Blog\n'
4 'Author of 20+ books on AI and I have 50+ US patents. Here I '
5 'talk about both technology and provide links to read my '
6 'published books online.\n'
7 "By registering you agree to Substack's Terms of Service, our "
8 'Privacy Policy, and our Information Collection Notice',
9 doc_id ='c6ed3ddd -b160-472b-9c7d-fd0446762cc8',
10 embedding =None,
11 doc_hash ='126a335ed76d5d79ad94470dd4dd06ab5556b9f1347e5be25ecc595e0290ab57\
12 ',
13 extra_info =None)]
14
15 ==QUESTION: How many patents does Mark have ?
16
17 ==RESPONSE:
18 Mark Watson has 50+ US patents.
19
20 ==QUESTION: How many books has Mark written ?
21
22 ==RESPONSE:
23 Mark has written 20+ books on AI.
OverviewofLlamaIndex 20
LlamaIndex/GPT-Index Case Study Wrap Up LlamaIndexisasetofdatastructuresandlibrarycodedesignedtomakeiteasiertouselargeexternal
knowledge bases such as Wikipedia. LlamaIndex createsavectorized index from your document
data,makingithighlyefficienttoquery. Itthenusesthisindextoidentifythemostrelevantsections
ofthedocumentbasedonthequery.
LlamaIndex is useful because it providesacentral interface to connect your LLM’s with external
dataandoffersdataconnectorstoyourexistingdatasourcesanddataformats(API’s,PDF’s,docs,
SQL,etc.). Itprovidesasimple,flexibleinterfacebetweenyourexternaldataandLLMs.
SomeprojectsthatuseLlamaIndexincludebuildingpersonalassistantswithLlamaIndexandGPT-
3.5,usingLlamaIndexfordocumentretrieval,andcombininganswersacrossdocuments.
Retrie
val Augmented Generation
(RAG) Applications TBD:thischapterwillbecompletebyMarch1,2023
Note to readers: this chapter was added February 2024 and supersedes some of the older material
inlaterchaptersonindexingandchattingaboutdatafromlocaltextandPDFdocumentsaswellas
datafromwebsites.
Retrieval Augmented Generation (RAG) Applications work by pre-processingauser’s query to
search for indexed document fragments that are semantically similar to the uer’s query. These
fragments are concatenated together as context text that is attached to the user’s query and then
passedoftoaLLMmodel. TheLLMcanpreferentiallyuseinformationinthiscontexttextaswell
asinnateknowledgestoredintheLLMtoprocessuserqueries.
Figur
e 2. RAG System Overview TBD:thischapterwillbecompletebyMarch1,2023
Using Google’s Knowledge Graph APIs With LangChain Google’sKnowledgeGraph(KG)isaknowledgebasethatGoogleusestoserverelevantinformation
inaninfoboxbesideitssearchresults. Itallowstheusertoseetheanswerinaglance,asaninstant
answer. The data is generated automatically fromavariety of sources, covering places, people,
businesses, and more. I worked at Google in 2013 onaproject that used their KG for an internal
project.
Google’spublicKnowledgeGraphSearchAPIletsyoufindentitiesintheGoogleKnowledgeGraph.
The API uses standard schema.org types and is compliant with the JSON-LD specification. It
supportsentitysearchandlookup.
You can use the Knowledge Graph Search API to build applications that make use of Google’s Knowledge Graph. For example, you can use the API to buildasearch engine that returns results
basedontheentitiesintheKnowledgeGraph.
In the next chapter we also use the public KGs DBPedia and Wikidata. One limitation of Google’s KG APIs is that it is designed for entity (people, places, organizations, etc.) lookup. When using DBPediaandWikidataitispossibletofindawiderrangeofinformationusingtheSPARQLquery
language, such as relationships between entities. You can use the Google KG APIs to find some
entity relationships, e.g., all the movies directed byaparticular director, or all the books written
byaparticular author. You can also use the API to find information like all the people who have
workedonaparticularmovie,oralltheactorswhohaveappearedinaparticularTVshow.
Setting Up To Access Google Knowledge Graph APIs To get an API key for Google’s Knowledge Graph Search API, you need to go to the Google API
Console, enable the Google Knowledge Graph Search API, and create an API key to use in your
project. YoucanthenusethisAPIkeytomakerequeststotheKnowledgeGraphSearchAPI.
Tocreateyourapplication’sAPIkey,followthesesteps:
• GototheAPIConsole.
• Fromtheprojectslist,selectaprojectorcreateanewone.
• If the APIs & services page isn’t already open, open the left side menu and select APIs &
services.
• Ontheleft,chooseCredentials.
• ClickCreatecredentialsandthenselectAPIkey.
UsingGoogle’sKnowledgeGraphAPIsWithLangChain 23
YoucanthenusethisAPIkeytomakerequeststotheKnowledgeGraphSearchAPIs.
WhenIuseGoogle’sAPIsIsettheaccesskeyin ~/.google_api_key andreadinthekeyusing:
1api_key =open(str(Path.home()) +"/.google_api_key").read()
You can also use environment variables to store access keys. Here isacode snippet for making an APIcalltogetinformationaboutme:
1import json
2from urllib.parse import urlencode
3from urllib.request import urlopen
4from pathlib import Path
5from pprint import pprint
6
7api_key =
8 open(str(Path.home()) +"/.google_api_key").read()
9query ="Mark Louis Watson"
10 service_url =
11 "https://kgsearch.googleapis.com/v1/entities:search"
12 params ={
13 "query": query,
14 "limit": 10,
15 "indent": True,
16 "key": api_key,
17 }
18 url =service_url +"?" +urlencode(params)
19 response =json.loads(urlopen(url) .read())
20 pprint(response)
TheJSON-LDoutputwouldlooklike:
1{'@context': {'@vocab': 'http://schema.org/',
2 'EntitySearchResult':
3 'goog:EntitySearchResult',
4 'detailedDescription':
5 'goog:detailedDescription',
6 'goog': 'http://schema.googleapis.com/',
7 'kg': 'http://g.co/kg',
8 'resultScore': 'goog:resultScore'},
9 '@type': 'ItemList',
10 'itemListElement': [{'@type': 'EntitySearchResult',
11 'result': {'@id': 'kg:/m/0b6_g82',
UsingGoogle’sKnowledgeGraphAPIsWithLangChain 24
12 '@type': ['Thing',
13 'Person'],
14 'description': 'Author',
15 'name':
16 'Mark Louis Watson',
17 'url':
18 'http://markwatson.com'},
19 'resultScore': 43}]}
InordertonotrepeatthecodeforgettingentityinformationfromtheGoogleKG,Iwroteautility Google_KG_helper.py thatencapsulatesthepreviouscodeandgeneralizesitintoamini-library:
1"""Client for calling Knowledge Graph Search API."""
2
3import json
4from urllib.parse import urlencode
5from urllib.request import urlopen
6from pathlib import Path
7from pprint import pprint
8
9api_key =
10 open(str(Path.home()) +"/.google_api_key").read()
11
12 # use Google search API to get information
13 # aboutanamed entity:
14
15 def get_entity_info (entity_name):
16 service_url =
17 "https://kgsearch.googleapis.com/v1/entities:search"
18 params ={
19 "query": entity_name,
20 "limit": 1,
21 "indent": True,
22 "key": api_key,
23 }
24 url =service_url +"?" +urlencode(params)
25 response =json.loads(urlopen(url) .read())
26 return response
27
28 def tree_traverse (a_dict):
29 ret =[]
30 def recur(dict_2, a_list):
31 ifisinstance (dict_2, dict):
UsingGoogle’sKnowledgeGraphAPIsWithLangChain 25
32 for key, value indict_2 .items():
33 ifkey in['name', 'description',
34 'articleBody']:
35 a_list +=[value]
36 recur(value, a_list)
37 ifisinstance (dict_2, list):
38 for xindict_2:
39 recur(x, a_list)
40 recur(a_dict, ret)
41 return ret
42
43
44 def get_context_text (entity_name):
45 json_data =get_entity_info(entity_name)
46 return ' '.join(tree_traverse(json_data))
47
48 if__name__ =="__main__":
49 get_context_text( "Bill Clinton")
Themaintestscriptisinthefile Google_Knowledge_Graph_Search.py :
1"""Example of Python client calling the
2 Knowledge Graph Search API."""
3
4from llama_index import GPTListIndex, Document
5
6import Google_KG_helper
7
8def kg_search (entity_name, *questions):
9 ret =""
10 context_text =
11 Google_KG_helper .get_context_text(entity_name)
12 print(f"Context text: {context_text }")
13 doc =Document(context_text)
14 index =GPTListIndex([doc])
15 for question inquestions:
16 response =index.query(question)
17 ret +=
18 f"QUESTION: {question }\nRESPONSE: {response }\n"
19 return ret
20
21 if__name__ =="__main__":
22 s=kg_search( "Bill Clinton",
UsingGoogle’sKnowledgeGraphAPIsWithLangChain 26
23 "When was Bill president?")
24 print(s)
Theexampleoutputis:
1$python Google_Knowledge_Graph_Search.py
2Context text: Bill Clinton 42nd U.S. President William Jefferson Clinton is an Ameri\
3can retired politician who served as the 42nd president of the United States from 19
493 to 2001.
5INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens
6INFO:root:> [build_index_from_documents] Total embedding token usage: 0 tokens
7INFO:root:> [query] Total LLM token usage: 77 tokens
8INFO:root:> [query] Total embedding token usage: 0 tokens
9QUESTION: When was Bill president?
10 RESPONSE:
11 Bill Clinton was president from 1993 to 2001.
Accessing Knowledge Graphs from Google, DBPedia, and Wikidata allows you to integrate real
worldfactsandknowledgewithyourapplications. WhileImostlyworkinthefieldofdeeplearning IfrequentlyalsouseKnowledgeGraphsinmyworkandinmypersonalresearch. Ithinkthatyou,
dear reader, might find accessing highly structured data in KGs to be more reliable and in many
casessimplerthanusingwebscraping.
Using DBPedia and WikiData as Knowledge Sources BothDBPedia1andWikidata2are public Knowledge Graphs (KGs) that store data as Resource Description Framework (RDF)3and are accessed through the SPARQL Query Language for RDF4.
Theexamplesforthisprojectareinthe GitHubrepositoryforthisbook5inthedirectory kg_search .
I am not going to spend much time here discussing RDF and SPARQL. Instead I ask you to read
online the introductory chapter Linked Data, the Semantic Web, and Knowledge Graphs in my
bookALispProgrammerLivinginPython-Land: TheHyProgrammingLanguage6.
Aswesawinthelastchapter,aKnowledgeGraph(thatIoftenabbreviateasKG)isagraphdatabase
usingaschema to define types (both objects and relationships between objects) and properties
that link property values to objects. The term “Knowledge Graph” is bothageneral term and
also sometimes refers to the specific Knowledge Graph used at Google which I worked with while
working there in 2013. Here, we use KG to reference the general technology of storing knowledge
ingraphdatabases.
DBPedia and Wikidata are similar, with some important differences. Here isasummary of some
similaritiesanddifferencesbetweenDBPediaandWikidata:
• BothprojectsaimtoprovidestructureddatafromWikipediainvariousformatsandlanguages.
Wikidataalsohasdatafromothersourcessoitcontainsmoredataandmorelanguages.
• BothprojectsuseRDFasacommondatamodelandSPARQLasaquerylanguage.
• DBPedia extracts data from the infoboxes in Wikipedia articles, while Wikidata collects data
enteredthroughitsinterfacesbybothusersandautomatedbots.
• Wikidatarequiressourcesforitsdata,whileDBPediadoesnot.
• DBpedia is more popular in the Semantic Web and Linked Open Data communities, while WikidataismoreintegratedwithWikimediaprojects.
To the last point: I personally prefer DBPedia when experimenting with the semantic web and
linked data, mostly because DBPedia URIs are human readable while Wikidata URIs are abstract.
ThefollowingURIsrepresentthetownIlivein,SedonaArizona:
• DBPedia: https://dbpedia.org/page/Sedona,_Arizona
1https://www.dbpedia.org
2https://www.wikidata.org/wiki/Wikidata:Main_Page
3https://www.w3.org/RDF/
4https://www.w3.org/TR/rdf-
sparql-query/
5https://github.com/mark-watson/langchain-book-examples
6https://leanpub.com/hy-lisp-python/read UsingDBPediaandWikiDataasKnowledgeSources 28
• Wikidata: https://www.wikidata.org/wiki/Q80041
InRDFweencloseURIsinanglebracketslike <https://www.wikidata.org/wiki/Q80041> .
IfyoureadthechapteronRDFandSPARQLinmybooklinkthatImentionedpreviously,thenyou
knowthatRDFdataisrepresentedbytripleswhereeachpartisnamed:
• subject
• property
• object We will look at two similar examples in this chapter, one using DBPedia and one using Wikidata.
BothserviceshaveSPARQLendpointwebapplicationsthatyouwillwanttouseforexploringboth KGs. WewilllookattheDBPediawebinterfacelater. HereistheWikidatawebinterface:
In
this SPARQL query the prefix wd:stands for Wikidata data while the prefix wdt:stands for Wikidatatype(orproperty). Theprefix rdfs:standsforRDFSchema.
UsingDBPediaandWikiDataasKnowledgeSources 29
Using DBPedia as a Data Source DBpediaisacommunity-drivenprojectthatextractsstructuredcontentfromWikipediaandmakes
itavailableonthewebasaKnowledgeGraph(KG).TheKGisavaluableresourceforresearchersand
developerswhoneedtoaccessstructureddatafromWikipedia. WiththeuseofSPARQLqueriesto DBpediaasadatasourcewecanwriteavarietyapplications,includingnaturallanguageprocessing,
machinelearning,anddataanalytics. WedemonstratetheeffectivenessofDBpediaasadatasource
by presenting several examples that illustrate its use in real-world applications. In my experience,
DBpedia isavaluable resource for researchers and developers who need to access structured data
fromWikipedia.
In general you will start projects using DBPedia by exploring available data using the web app
https://dbpedia.org/sparql thatcanbeseeninthisscreenshot:
The
following listing of file dbpedia_generate_rdf_as_nt.py shows Python code for making a SPARQLquerytoDBPediaandsavingtheresultsasRDFtriplesinNTformatinalocaltextfile:
UsingDBPediaandWikiDataasKnowledgeSources 30
1from SPARQLWrapper import SPARQLWrapper
2from rdflib import Graph
3
4sparql =SPARQLWrapper( "http://dbpedia.org/sparql")
5sparql .setQuery( """
6 PREFIX dbpedia-owl: <http://dbpedia.org/ontology/>
7 PREFIX dbpedia: <http://dbpedia.org/resource>
8 PREFIX dbpprop: <http://dbpedia.org/property>
9
10 CONSTRUCT {
11 ?city dbpedia-owl:country ?country .
12 ?city rdfs:label ?citylabel .
13 ?country rdfs:label ?countrylabel .
14 <http://dbpedia.org/ontology/country> rdfs:label "country"@en .
15 }
16 WHERE {
17 ?city rdf:type dbpedia-owl:City .
18 ?city rdfs:label ?citylabel .
19 ?city dbpedia-owl:country ?country .
20 ?country rdfs:label ?countrylabel .
21 FILTER (lang(?citylabel) = 'en')
22 FILTER (lang(?countrylabel) = 'en')
23 }
24 LIMIT 50
25 """)
26 sparql .setReturnFormat( "rdf")
27 results =sparql .query() .convert()
28
29 g=Graph()
30 g.parse(data =results .serialize( format ="xml"), format ="xml")
31
32 print("\nresults: \n")
33 results =g.serialize( format ="nt").encode( "utf-8").decode( 'utf-8')
34 print(results)
35
36 text_file =open("sample.nt", "w")
37 text_file .write(results)
38 text_file .close()
Hereistheprintedoutputfromrunningthisscript(mostoutputnotshown,andmanuallyeditedto
fitpagewidth):
UsingDBPediaandWikiDataasKnowledgeSources 31
1 $python generate_rdf_as_nt.py
2results:
3
4<http://dbpedia.org/resource/Ethiopia>
5 <http://www.w3.org/2000/01/rdf-schema#label>
6 "Ethiopia"@en .
7<http://dbpedia.org/resource/Valentin_Alsina,_Buenos_Aires>
8 <http://www.w3.org/2000/01/rdf-schema#label>
9 "Valentin Alsina, Buenos Aires"@en .
10 <http://dbpedia.org/resource/Davyd-Haradok>
11 <http://dbpedia.org/ontology/country>
12 <http://dbpedia.org/resource/Belarus> .
13 <http://dbpedia.org/resource/Davyd-Haradok>
14 <http://www.w3.org/2000/01/rdf-schema#label>
15 "Davyd-Haradok"@en .
16 <http://dbpedia.org/resource/Belarus>
17 <http://www.w3.org/2000/01/rdf-schema#label>
18 "Belarus"@en .
19 ...
This output was written toalocal file sample.nt . I divided this example into two separate Python
scripts because I thought it would be easier for you, dear reader, to experiment with fetching RDF
dataseparatelyfromusingaLLMtoprocesstheRDFdata. Inproductionyoumaywanttocombine KGquerieswithsemanticanalysis.
Thiscodeexampledemonstratestheuseofthe GPTSimpleVectorIndex forqueryingRDFdataand
retrieving information about countries. The function download_loader loads data importers by
stringname. WhileitisnotatypesafetoloadaPythonclassbynameusingastring,ifyoumisspell
thenameoftheclasstoloadthecallto download_loader thenaPython ValueError(“Loader class
name not found in library”) erroristhrown. TheGPTSimpleVectorIndexclassrepresentsanindex
data structure that can be used to efficiently search and retrieve information from the RDF data.
ThisissimilartoothertypesofLlamaIndexvectorindextypesfordifferenttypesofdatasources.
Hereisthescript dbpedia_rdf_query.py :
1"Example from documentation"
2
3from llama_index import GPTSimpleVectorIndex, Document
4from llama_index import download_loader
5
6RDFReader =download_loader( "RDFReader")
7doc =RDFReader() .load_data( "sample.nt")
8index =GPTSimpleVectorIndex(doc)
9
UsingDBPediaandWikiDataasKnowledgeSources 32
10 result =index.query( "list all countries inaquoted Python array, then explain why")
11
12 print(result .response)
Hereistheoutput:
1$python rdf_query.py
2INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens
3INFO:root:> [build_index_from_documents] Total embedding token usage: 761 tokens
4INFO:root:> [query] Total LLM token usage: 921 tokens
5INFO:root:> [query] Total embedding token usage: 12 tokens
6
7['Argentina', 'French Polynesia', 'Democratic Republic of the Congo', 'Benin', 'Ethi\
8opia', 'Australia', 'Uzbekistan', 'Tanzania', 'Albania', 'Belarus', 'Vanuatu', 'Arme
9nia', 'Syria', 'Andorra', 'Venezuela', 'France', 'Vietnam', 'Azerbaijan']
10
11 This isalist of all the countries mentioned in the context information. All of the\
12 countries are listed in the context information, so this list is complete.
Whyarethereonly18countrieslisted? InthescriptusedtoperformaSPARQLqueryonDBPedia,
wehadastatement LIMIT 50 attheendofthequerysoonly50RDFtripleswerewrittentothefile
sample.nt thatonlycontainsdatafor18countries.
Using Wikidata as a Data Source ItisslightlymoredifficultexploringWikidatacomparedtoDBPedia. Let’srevisitgettinginforma-
tionaboutmyhometownofSedonaArizona.
In writing this example, I experimented with SPARQL queries using the Wikidata SPARQL web
app7.
We can start by finding RDF statements with the object value being “Sedona” using the Wikidata
webapp:
1select *where {
2 ?s ?p "Sedona"@en
3}LIMIT 30
Firstwewriteahelperutilitytogatherprompttextforanentityname(e.g.,nameofaperson,place,
etc.) inthefile wikidata_generate_prompt_text.py :
7https://query.wikidata.org UsingDBPediaandWikiDataasKnowledgeSources 33
1from SPARQLWrapper import SPARQLWrapper, JSON
2from rdflib import Graph
3import pandas aspd
4
5def get_possible_entity_uris_from_wikidata (entity_name):
6 sparql =SPARQLWrapper( "https://query.wikidata.org/sparql")
7 sparql .setQuery( """
8 SELECT ?entity ?entityLabel WHERE {
9 ?entity rdfs:label "%s"@en .
10 } limit 5
11 """ %entity_name)
12
13 sparql .setReturnFormat(JSON)
14 results =sparql .query() .convert()
15
16 results =pd.json_normalize(results[ 'results']['bindings']).values .tolist()
17 results =["<" +x[1] +">" for xinresults]
18 return [*set(results)] # remove duplicates
19
20 def wikidata_query_to_df (entity_uri):
21 sparql =SPARQLWrapper( "https://query.wikidata.org/sparql")
22 sparql .setQuery( """
23 SELECT ?description ?is_a_type_of WHERE {
24 %sschema:description ?description FILTER (lang(?description) = 'en') .
25 %swdt:P31 ?instanceOf .
26 ?instanceOf rdfs:label ?is_a_type_of FILTER (lang(?is_a_type_of) = 'en') .
27 } limit 10
28 """ %(entity_uri, entity_uri))
29
30 sparql .setReturnFormat(JSON)
31 results =sparql .query() .convert()
32 results2 =pd.json_normalize(results[ 'results']['bindings'])
33 prompt_text =""
34 for index, row inresults2 .iterrows():
35 prompt_text +=row['description.value'] +" isatype of " +row['is_a_type_ \
36 of.value'] +"\n"
37 return prompt_text
38
39 def generate_prompt_text (entity_name):
40 entity_uris =get_possible_entity_uris_from_wikidata(entity_name)
41 prompt_text =""
42 for entity_uri inentity_uris:
43 p=wikidata_query_to_df(entity_uri)
UsingDBPediaandWikiDataasKnowledgeSources 34
44 if"disambiguation page" not in p:
45 prompt_text +=entity_name +" is " +wikidata_query_to_df(entity_uri)
46 return prompt_text
47
48 if__name__ =="__main__":
49 print("Sedona:", generate_prompt_text( "Sedona"))
50 print("California:",
51 generate_prompt_text( "California"))
52 print("Bill Clinton:",
53 generate_prompt_text( "Bill Clinton"))
54 print("Donald Trump:",
55 generate_prompt_text( "Donald Trump"))
Thisutilitydoesmostoftheworkingettingprompttextforanentity.
TheGPTTreeIndex classissimilartootherLlamaIndexindexclasses. Thisclassbuildsatree-based
index of the prompt texts, which can be used to retrieve information based on the input question.
In LlamaIndex, a GPTTreeIndex is used to select the child node(s) to send the query down to. A
GPTKeywordTableIndex uses keyword matching, and a GPTVectorStoreIndex uses embedding
cosinesimilarity. Thechoiceofwhichindexclasstousedependsonhowmuchtextisbeingindexed,
whatthegranularityofsubjectmatterinthetextis,andifyouwantsummarization.
GPTTreeIndex isalsomoreefficientthan GPTSimpleVectorIndex becauseitusesatreestructure
tostorethedata. Thisallowsforfastersearchingandretrievalofdatacomparedtoalinearlistindex
classlike GPTSimpleVectorIndex .
TheLlamaIndexcodeisrelativelyeasytoimplementinthescript wikidata_query.py (editedtofit
pagewidth):
1from llama_index import StringIterableReader, GPTTreeIndex
2from wikidata_generate_prompt_text import generate_prompt_text
3
4def wd_query (question, *entity_names):
5 prompt_texts =[]
6 for entity_name inentity_names:
7 prompt_texts +=
8 [generate_prompt_text(entity_name)]
9 documents =
10 StringIterableReader() .load_data(texts =prompt_texts)
11 index =GPTTreeIndex(documents)
12 index =index.as_query_engine(child_branching_factor =2)
13 return index .query(question)
14
15 if__name__ =="__main__":
UsingDBPediaandWikiDataasKnowledgeSources 35
16 print("Sedona:", wd_query("What is Sedona?", "Sedona"))
17 print("California:",
18 wd_query( "What is California?", "California"))
19 print("Bill Clinton:",
20 wd_query( "When was Bill Clinton president?",
21 "Bill Clinton"))
22 print("Donald Trump:",
23 wd_query( "Who is Donald Trump?",
24 "Donald Trump"))
Hereisthetestoutput(withsomelinesremoved):
1$python wikidata_query.py
2Total LLM token usage: 162 tokens
3INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] INFO:lla\
4ma_index.indices.query.tree.leaf_query:> Starting query: What is Sedona?
5INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 154 to\
6kens
7Sedona: Sedona isacity in the United States located in the counties of Yavapai and\
8 Coconino, Arizona. It is also the title of a 2012 film, a company, and a 2015 singl
9e by Houndmouth.
10
11 Total LLM token usage: 191 tokens
12 INFO:llama_index.indices.query.tree.leaf_query:> Starting query: What is California?
13 California: California is a U.S. state in the United States of America.
14
15 Total LLM token usage: 138 tokens
16 INFO:llama_index.indices.query.tree.leaf_query:> Starting query: When was Bill Clint\
17 on president?
18 Bill Clinton: Bill Clinton was the 42nd President of the United States from 1993 to \
19 2001.
20
21 Total LLM token usage: 159 tokens
22 INFO:llama_index.indices.query.tree.leaf_query:> Starting query: Who is Donald Trump?
23 Donald Trump: Donald Trump is the 45th President of the United States, serving from \
24 2017 to 2021.
Using LLMs To Organize Information
in Our Google Drives Mydigitallifeconsistsofwriting,workingasanAIpractitioner,andlearningactivitiesthatIjustify
with my self-imageof a “gentlemanscientist.” Cloud storagelikeGitHub, Google Drive, Microsoft OneDrive,andiCloudarecentraltomyactivities.
AbouttenyearsagoIspenttwomonthsofmytimewritingasysteminClojurethatwasplannedto
bemyowncustomandpersonalDropBox,augmentedwithvariousNLPtoolsandaFireFoxplugin
tosendwebclippingsdirectlytomypersonalsystem. Tobehonest,Istoppedusingmyownproject
afterafew months because the time it took to organizemy information wasagreater opportunity
costthanthevalueIreceived.
In this chapter I am going to walk youthroughparts ofanewsystem that I am developingfor my
own personal use to help me organize my material on Google Drive (and eventually other cloud
services). Don’tbesurprisedifthecompletedprojectisanadditionalexampleinafutureeditionof
thisbook!
WiththeGooglesetupdirectionslistedbelow,youwillgetapop-upwebbrowsingwindowwitha
warninglike(thisshowsmyGmailaddress,youshouldseeyourownGmailaddresshereassuming
thatyouhaverecentlyloggedintoGmailusingyourdefaultwebbrowser):
UsingLLMsToOrganizeInformationinOurGoogleDrives 37
Y
ouwillneedtofirstclick Advanced andthenclicklink Go to GoogleAPIExamples (unsafe) link
inthelowerleftcornerandthentemporarilyauthorizethisexampleonyourGmailaccount.
Setting Up Requirements.
Youneedtocreateacredentialat https://console.cloud.google.com/cloud-resource-manager (copied
fromthePyDrivedocumentation1,changingapplicationtypeto“Desktop”):
• Searchfor‘GoogleDriveAPI’,selecttheentry,andclick‘Enable’.
• Select‘Credentials’fromtheleftmenu,click‘CreateCredentials’,select‘OAuthclientID’.
• Now, the product name and consent screen need to be set -> click ‘Configure consent screen’
andfollowtheinstructions. Oncefinished:
• Select‘Applicationtype’tobeDesktopapplication.
• Enteranappropriatename.
1https://pythonhosted.org/PyDrive/quickstart.html UsingLLMsToOrganizeInformationinOurGoogleDrives 38
• Inputhttp://localhost:8080for‘AuthorizedJavaScriptorigins’.
• Inputhttp://localhost:8080/for‘AuthorizedredirectURIs’.
• Click‘Save’.
• Click‘DownloadJSON’ontherightsideofClientIDtodownloadclient_secret_.json. Copythe
downloadedJSONcredentialfiletotheexampledirectory google_drive_llm forthischapter.
Write Utility To Fetch All Text Files From Top Level Google Drive Folder For this example we will just authenticate our test script with Google, and copy all top level text
fileswithnamesendingwith“.txt”tothelocalfilesystemin subdirectory data. Thecodeisinthe
directory google_drive_llm infile fetch_txt_files.py (editedtofitpagewidth):
1from pydrive.auth import GoogleAuth
2from pydrive.drive import GoogleDrive
3from pathlib import Path
4
5# good GD search docs:
6# https://developers.google.com/drive/api/guides/search-files
7
8# Authenticate with Google
9gauth =GoogleAuth()
10 gauth.LocalWebserverAuth()
11 drive =GoogleDrive(gauth)
12
13 def get_txt_files (dir_id ='root'):
14 " get all plain text files with .txt extension in top level Google Drive directo \
15 ry "
16
17 file_list =drive.ListFile({ 'q': f"'{dir_id }' in parents and trashed=false"}).Ge\
18 tList()
19 for file1 infile_list:
20 print('title: %s, id: %s' %(file1[ 'title'], file1['id']))
21 return [[file1[ 'title'], file1['id'], file1.GetContentString()]
22 for file1 infile_list
23 iffile1[ 'title'].endswith( ".txt")]
24
25 def create_test_file ():
26 " not currently used, but useful for testing. "
27
UsingLLMsToOrganizeInformationinOurGoogleDrives 39
28 # Create GoogleDriveFile instance with title 'Hello.txt':
29 file1 =drive.CreateFile({ 'title': 'Hello.txt'})
30 file1.SetContentString( 'Hello World!')
31 file1.Upload()
32
33 def test():
34 fl=get_txt_files()
35 for finfl:
36 print(f)
37 file1 =open("data/" +f[0],"w")
38 file1.write(f[ 2])
39 file1.close()
40
41 if__name__ =='__main__':
42 test()
For testing I just have one text file with the file extension “.txt” on my Google Drive so my output
from running this script looks like the following listing. I edited the output to change my file IDs
andtoonlyprintafewlinesofthedebugprintoutoffiletitles.
1$python fetch_txt_files.py
2Your browser has been opened to visit:
3
4 https://accounts.google.com/o/oauth2/auth?client_id=529311921932-xsmj3hhiplr0dhq\
5jln13fo4rrtvoslo8.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3B6
6180%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&res
7ponse_type=code
8
9Authentication successful.
10
11 title: testdata, id: 1TZ9bnL5XYQvKACJw8VoKWdVJ8jeCszJ
12 title: sports.txt, id: 18RN4ojvURWt5yoKNtDdAJbh4fvmRpzwb
13 title: Anaconda blog article, id: 1kpLaYQA4Ao8ZbdFaXU209hg-z0tv1xA7YOQ4L8y8NbU
14 title: backups_2023, id: 1-k_r1HTfuZRWN7vwWWsYqfssl0C96J2x
15 title: Work notes, id: 1fDyHyZtKI-0oRNabA_P41LltYjGoek21
16 title: Sedona Writing Group Contact List, id: 1zK-5v9OQUfy8Sw33nTCl9vnL822hL1w
17 ...
18 ['sports.txt', '18RN4ojvURWt5yoKNtDdAJbh4fvmRpzwb', 'Sport is generally recognised a\
19 s activities based in physical athleticism or physical dexterity.[3] Sports are usua
20 lly governed by rules to ensure fair competition and consistent adjudication of the
21 winner.\n\n"Sport" comes from the Old French desport meaning "leisure", with the old
22 est definition in English from around 1300 being "anything humans find amusing or en
23 tertaining".[4]\n\nOther bodies advocate widening the definition of sport to include UsingLLMsToOrganizeInformationinOurGoogleDrives 40
24 all physical activity and exercise. For instance, the Council of Europe include all
25 forms of physical exercise, including those completed just for fun.\n\n']
Generate Vector Indices for Files in Specific Google Drive Directories TheexamplescriptinthelastsectionshouldhavecreatedcopiesofthetextfilesinyouhomeGoogle Documentsdirectorythatendwith“.txt”. Here,weusethesameLlamaIndextestcodethatweused
inapreviouschapter. Thetestscript index_and_QA.py islistedhere:
1# make sure you set the following environment variable is set:
2# OPENAI_API_KEY
3
4from llama_index import GPTSimpleVectorIndex, SimpleDirectoryReader
5documents =SimpleDirectoryReader( 'data').load_data()
6index =GPTSimpleVectorIndex(documents)
7
8# save to disk
9index.save_to_disk( 'index.json')
10 # load from disk
11 index =GPTSimpleVectorIndex .load_from_disk( 'index.json')
12
13 # search foradocument
14 print(index .query( "What is the definition of sport?"))
Formytestfile,theoutputlookslike:
1$python index_and_QA.py
2INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total LL\
3M token usage: 0 tokens
4INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total em\
5bedding token usage: 111 tokens
6INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 202 to\
7kens
8INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: \
97 tokens
10
11 Sport is generally recognised as activities based in physical athleticism or physica\
12 l dexterity that are governed by rules to ensure fair competition and consistent adj
13 udication of the winner. It is anything humans find amusing or entertaining, and can
14 include all forms of physical exercise, even those completed just for fun.
UsingLLMsToOrganizeInformationinOurGoogleDrives 41
Itisinterestingtoseehowthequeryresultisrewritteninaniceform,comparedtotherawtextin
thefile sports.txt onmyGoogleDrive:
1$cat data/sports.txt
2Sport is generally recognised as activities based in physical athleticism or physica\
3l dexterity.[3] Sports are usually governed by rules to ensure fair competition and
4consistent adjudication of the winner.
5
6"Sport" comes from the Old French desport meaning "leisure", with the oldest definit\
7ion in English from around 1300 being "anything humans find amusing or entertaining"
8.[4]
9
10 Other bodies advocate widening the definition of sport to include all physical activ\
11 ity and exercise. For instance, the Council of Europe include all forms of physical
12 exercise, including those completed just for fun.
Google Drive Example Wrap Up IfyoualreadyuseGoogleDrivetostoreyourworkingnotesandotherdocuments,thenyoumight
want to expand the simple example in this chapter to build your own query system for your
documents. InadditiontoGoogleDrive,IalsouseMicrosoftOffice365andOneDriveinmywork
andpersonalprojects.
I haven’t written my own connectors yet for OneDrive but this is on my personal to-do list using
theMicrosoftlibrary https://github.com/OneDrive/onedrive-sdk-python .
Using Zapier Integrations With GMail
and Google Calendar Zapierisaserviceforwritingintegrationswithhundredsofcloudservices. Herewewillwritesome
demosforwritingautomaticintegrationswithGMailandGoogleCalendar.
UsingtheZapierserviceissimple. Youneedtoregistertheservicesyouwanttointeractwithonthe Zapier developer web site and then you can express how you want to interact with services using
naturallanguageprompts.
Set Up Development Environment Youwillneedadeveloperkeyfor ZapierNaturalLanguageActionsAPI1.Gotothislinkedwebpage
and look for “Dev App” in the “Provider Name” column. Ifakey does not exist, you’ll need to set
upanactiontocreateakey. Click“SetupActions”andfollowtheinstructions. Yourkeywillbein
the Personal API Key column for the “Dev App.” Click to reveal and copy your key. You can read
thedocumentation2.
WhenIsetupmyZapieraccountIsetupthreeZapierNaturalLanguageActions:
• Gmail: FindEmail
• Gmail: SendEmail
• GoogleCalendar: FindEvent IfyoudothesamethenyouwillseetheZapierregisteredactions:
1https://nla.zapier.com/get-
started/
2https://nla.zapier.com/api/v1/dynamic/docs UsingZapierIntegrationsWithGMailandGoogleCalendar 43
Sending
a Test GMail Inthefollowingexamplereplace TEST_EMAIL_ADDRESS withanemailaddressthatyoucanuse
fortesting.
UsingZapierIntegrationsWithGMailandGoogleCalendar 44
1from langchain.llms import OpenAI
2from langchain.agents import initialize_agent
3from langchain.agents.agent_toolkits import ZapierToolkit
4from langchain.utilities.zapier import ZapierNLAWrapper
5
6llm =OpenAI(temperature =0)
7zapier =ZapierNLAWrapper()
8toolkit =ZapierToolkit .from_zapier_nla_wrapper(zapier)
9agent =initialize_agent(toolkit .get_tools(), llm, agent ="zero-shot-react-descriptio \
10 n", verbose=True)
11
12 agent.run("Send an Email to TEST_EMAIL_ADDRESS via gmail that isapitch for hiring \
13 Mark Watson asaconsultant for deep learning and large language models")
Hereisthesampleoutput:
1$python send_gmail.py
2
3
4> Entering new AgentExecutor chain...
5 I need to use the Gmail: Send Email tool
6Action: Gmail: Send Email
7Action Input: Send an email to TEST_EMAIL_ADDRESS with the subject "Pitch for Hiring\
8 Mark Watson as a Consultant for Deep Learning and Large Language Models" and the bo
9dy "Dear Mark Watson, I am writing to you to pitch the idea of hiring you asaconsu
10 ltant for deep learning and large language models. I believe you have the expertise
11 and experience to help us achieve our goals. Please let me know if you are intereste
12 d in discussing further. Thank you for your time."
13 Cc: not enough information provided in the instruction, missing Cc
14 Observation: {"labelIds": "SENT"}
15 Thought: I now know the final answer
16 Final Answer: An email has been sent to TEST_EMAIL_ADDRESS with the subject "Pitch f\
17 or Hiring Mark Watson as a Consultant for Deep Learning and Large Language Models" a
18 nd the body "Dear Mark Watson, I am writing to you to pitch the idea of hiring you a
19 saconsultant for deep learning and large language models. I believe you have the e
20 xpertise and experience to help us achieve our goals. Please let me know if you are
21 interested in discussing further. Thank you for your time."
22
23 > Finished chain.
UsingZapierIntegrationsWithGMailandGoogleCalendar 45
Google Calendar Integration Example AssumingthatyouconfiguredtheZapierNaturalLanguageAction“GoogleCalendar: FindEvent”
thenthesamecodeweusedtosendanemailinthelastsectionworksforcheckingcalendarentries,
youjustneedtochangethenaturallanguageprompt:
1from langchain.llms import OpenAI
2from langchain.agents import initialize_agent
3from langchain.agents.agent_toolkits import ZapierToolkit
4from langchain.utilities.zapier import ZapierNLAWrapper
5
6llm =OpenAI(temperature =0)
7zapier =ZapierNLAWrapper()
8toolkit =ZapierToolkit .from_zapier_nla_wrapper(zapier)
9agent =initialize_agent(toolkit .get_tools(), llm,
10 agent="zero-shot-react-description", verbose=True)
11
12 agent.run("Get my Google Calendar entries for tomorrow")
Andtheoutputlookslike:
1$python get_google_calendar.py
2
3> Entering new AgentExecutor chain...
4 I need to find events in my Google Calendar
5Action: Google Calendar: Find Event
6Action Input: Find events in my Google Calendar tomorrow
7Observation: {"location": "Greg to call Mark on (928) XXX-ZZZZ", "kind": "calendar#e\
8vent", "end__dateTime": "2023-03-23T10:00:00-07:00", "status": "confirmed", "end__da
9teTime_pretty": "Mar 23, 2023 10:00AM", "htmlLink": "https://zpr.io/WWWWWWWW"}
10 Thought: I now know the final answer
11 Final Answer: I have an event in my Google Calendar tomorrow at 10:00AM.
12
13 > Finished chain.
Ieditedthisoutputtoremovesomeprivateinformation.
Natur
al Language SQLite Database Queries With LangChain The LangChain library support fof SQLite databases uses the Python library SQLAlchemy for
database connections. This abstraction layer allows LangChain to use the same logic and models
forotherrelationaldatabases.
IhavealongworkhistoryofwritingnaturallanguageinterfacesforrelationaldatabasesthatIwill
review in the chapter wrap up. For now, I invite you to be amazed at how simple it is to write the LangChainscriptsforqueryingadatabaseinnaturallanguage.
WewillusetheSQlitesampledatabasefromtheSQLiteTutorialwebsite:
1https://www.sqlitetutorial.net/sqlite-sample-database/
This database has 11 tables. The above URI has documentation for this database so please takeaminutetoreviewthe tableschemadiagramandtextdescription1.
This example is derived from the LangChain documentation2. We use three classes from the
langchainlibrary:
• OpenAI:AclassthatrepresentstheOpenAIlanguagemodel,whichiscapableofunderstanding
naturallanguageandgeneratingaresponse.
• SQLDatabase: AclassthatrepresentsaconnectiontoanSQLdatabase.
• SQLDatabaseChain: AclassthatconnectstheOpenAIlanguagemodelwiththeSQLdatabase
toallownaturallanguagequerying.
The temperature parameter set to 0 in this example. The temperature parameter controls the
randomness of the generated output. A lower value (like 0) makes the model’s output more
deterministicandfocused,whileahighervalueintroducesmorerandomness(or“creativity”). The
run method of the db_chain object translates the natural language query into an appropriate SQL
query, executeitontheconnecteddatabase, andthenreturnstheresultconvertingtheoutputinto
naturallanguage.
1https://www.sqlitetutorial.net/sqlite-
sample-database/
2https://langchain.readthedocs.io/en/latest/modules/chains/examples/sqlite.html NaturalLanguageSQLiteDatabaseQueriesWithLangChain 47
1# SQLite NLP Query Demo Script
2
3from langchain import OpenAI, SQLDatabase
4from langchain import SQLDatabaseChain
5
6db=SQLDatabase .from_uri( "sqlite:///chinook.db")
7llm =OpenAI(temperature =0)
8
9db_chain =SQLDatabaseChain(llm =llm, database=db,
10 verbose =True)
11
12 db_chain .run("How many employees are there?")
13 db_chain .run("What is the name of the first employee?")
14 db_chain .run("Which customer has the most invoices?")
15 db_chain .run("List all music genres in the database")
Theoutput(editedforbrevity)showsthegeneratedSQLqueriesandthequeryresults:
1$python sqlite_chat_test.py
2
3> Entering new SQLDatabaseChain chain...
4How many employees are there?
5 SELECT COUNT(*) FROM employees;
6SQLResult: [(8,)]
7Answer: There are 8 employees.
8> Finished chain.
9
10 > Entering new SQLDatabaseChain chain...
11 What is the name of the first employee?
12 SELECT FirstName, LastName FROM employees WHERE EmployeeId = 1;
13 SQLResult: [('Andrew', 'Adams')]
14 Answer: The first employee is Andrew Adams.
15 > Finished chain.
16
17 > Entering new SQLDatabaseChain chain...
18 Which customer has the most invoices?
19 SELECT customers.FirstName, customers.LastName, COUNT(invoices.InvoiceId) AS Number\
20 OfInvoices FROM customers INNER JOIN invoices ON customers.CustomerId = invoices.Cus
21 tomerId GROUP BY customers.CustomerId ORDER BY NumberOfInvoices DESC LIMIT 5;
22 SQLResult: [('Luis', 'Goncalves', 7), ('Leonie', 'Kohler', 7), ('Francois', 'Trembla\
23 y', 7), ('Bjorn', 'Hansen', 7), ('Frantisek', 'Wichterlova', 7)]
24 Answer: Luis Goncalves has the most invoices with 7.
25 > Finished chain.
NaturalLanguageSQLiteDatabaseQueriesWithLangChain 48
26
27 > Entering new SQLDatabaseChain chain...
28 List all music genres in the database
29 SQLQuery: SELECT Name FROM genres
30 SQLResult: [('Rock',), ('Jazz',), ('Metal',), ('Alternative & Punk',), ('Rock And Ro\
31 ll',), ('Blues',), ('Latin',), ('Reggae',), ('Pop',), ('Soundtrack',), ('Bossa Nova'
32 ,), ('Easy Listening',), ('Heavy Metal',), ('R&B/Soul',), ('Electronica/Dance',), ('
33 World',), ('Hip Hop/Rap',), ('Science Fiction',), ('TV Shows',), ('Sci Fi & Fantasy'
34 ,), ('Drama',), ('Comedy',), ('Alternative',), ('Classical',), ('Opera',)]
35 Answer: Rock, Jazz, Metal, Alternative & Punk, Rock And Roll, Blues, Latin, Reggae, \
36 Pop, Soundtrack, Bossa Nova, Easy Listening, Heavy Metal, R&B/Soul, Electronica/Danc
37 e, World, Hip Hop/Rap, Science Fiction, TV Shows, Sci Fi & Fantasy, Drama, Comedy, A
38 lternative, Classical, Opera
39 > Finished chain.
Natural Language Database Query Wrap Up IhadanexampleIwroteforthefirsttwoeditionsofmy JavaAIbook3(Ilaterremovedthisexample
becausethecodewastoolongandtoodifficulttofollow). IlaterreworkedthisexampleinCommon Lispandusedbothversionsinseveralconsultingprojectsinthelate1990sandearly2000s.
The last book I wrote Practical Python Artificial Intelligence Programming4used an OpenAI ex-
amplehttps://github.com/openai/openai-cookbook/blob/main/examples/Backtranslation_of_SQL_
queries.py thatshowsrelativelysimplecode(relativetomyolderhand-writtenJavaandCommon Lispcode)foraNLPdatabaseinterface.
Compared to the elegant support for NLP database queries in LangChain, the previous examples
havelimitedpowerandrequiredalotmorecode. AsIwritethisinMarch2023,itisagoodfeeling
thatfortherestofmycareer,NLPdatabaseaccessisnowasolvedproblem!
3https://leanpub.com/javaai
4https://leanpub.com/pythonai Examples Using Hugging Face Open Source Models To start with you will need to createafree account on the Hugging Face Hub1and get an API key
andinstall:
1pip install --upgrade huggingface_hub YouneedtosetthefollowingenvironmentvariabletoyourHuggingFaceHubaccesstoken:
1HUGGINGFACEHUB_API_TOKEN
SofarinthisbookwehavebeenusingtheOpenAILLMwrapper:
1from langchain.llms import OpenAI
HerewewillusethealternativeHuggingFacewrapperclass:
1from langchain import HuggingFaceHub TheLangChainlibraryhidesmostofthedetailsofusingbothAPIs. Thisisareallygoodthing. Ihave
hadafew discussions on social tech media with people who object to the non open source nature
ofOpenAI.WhileIliketheconvenienceofusingOpenAI’sAPIs,Ialwaysliketohavealternatives
forproprietarytechnologyIuse.
The Hugging Face Hub endpoint in LangChain connects to the Hugging Face Hub and runs the
models via their free inference endpoints. We need a Hugging Face account and API key to use
these endpoints3. There exists two Hugging Face LLM wrappers, one foralocal pipeline and one
foramodel hosted on Hugging Face Hub. Note that these wrappers only work for models that
support the text2text-generation and text-generation tasks. Text2text-generation refers to the task
ofgeneratingatextsequencefromanothertextsequence. Forexample,generatingasummaryofa
longarticle. Text-generationreferstothetaskofgeneratingatextsequencefromscratch.
Using LangChain as a Wrapper for Hugging Face Prediction Model APIs We will start withasimple example using the prompt text support in LangChain. The following
exampleisinthescript simple_example.py :
1https://huggingface.co/docs/huggingface_hub/index ExamplesUsingHuggingFaceOpenSourceModels 50
1from langchain import HuggingFaceHub, LLMChain
2from langchain.prompts import PromptTemplate
3
4hub_llm =HuggingFaceHub(
5 repo_id ='google/flan-t5-xl',
6 model_kwargs ={'temperature':1e-6}
7)
8
9prompt =PromptTemplate(
10 input_variables =["name"],
11 template ="What year did {name} get elected as president?",
12 )
13
14 llm_chain =LLMChain(prompt =prompt, llm=hub_llm)
15
16 print(llm_chain .run("George Bush"))
By changing justafew lines of code, you can run many of the examples in this book using the HuggingFaceAPIsinplaceoftheOpenAIAPIs.
The LangChain documentation lists the source code forawrapper to use local Hugging Face
embeddings here2.
Creating a Custom LlamaIndex Hugging Face LLM
Wrapper Class That Runs on Your Laptop We will be downloading the Hugging Face model facebook/opt-iml-1.3b that is a 2.6
gigabyte file. This model is downloaded the first time it is requested and is then cached in
~/.cache/huggingface/hub forlaterreuse.
This example is modified from an example for custom LLMs in the LlamaIndex documentation3.
Note that I have usedamuch smaller model in this example and reduced the prompt and output
textsize.
2https://langchain.readthedocs.io/en/latest/_modules/langchain/embeddings/self_hosted_hugging_face.html
3https://github.com/jerryjliu/llama_index/blob/main/docs/how_to/customization/custom_llms.md ExamplesUsingHuggingFaceOpenSourceModels 51
1# Derived from example:
2# https://gpt-index.readthedocs.io/en/latest/how_to/custom_llms.html
3
4import time
5import torch
6from langchain.llms.base import LLM
7from llama_index import SimpleDirectoryReader, LangchainEmbedding
8from llama_index import GPTListIndex, PromptHelper
9from llama_index import LLMPredictor
10 from transformers import pipeline
11
12 max_input_size = 512
13 num_output = 64
14 max_chunk_overlap = 10
15 prompt_helper =PromptHelper(max_input_size, num_output, max_chunk_overlap)
16
17 class CustomLLM (LLM):
18 model_name ="facebook/opt-iml-1.3b"
19 # I am not using a GPU, but you can add device="cuda:0"
20 # to the pipeline call if you havealocal GPU or
21 # are running this on Google Colab:
22 pipeline =pipeline( "text-generation", model=model_name,
23 model_kwargs ={"torch_dtype":torch .bfloat16})
24
25 def _call(self, prompt, stop =None):
26 prompt_length =len(prompt)
27 response =self.pipeline(prompt, max_new_tokens =num_output)
28 first_response =response[ 0]["generated_text"]
29 # only return newly generated tokens
30 returned_text =first_response[prompt_length:]
31 return returned_text
32
33 @property
34 def _identifying_params (self):
35 return {"name_of_model": self.model_name}
36
37 @property
38 def _llm_type (self):
39 return "custom"
40
41 time1 =time.time()
42
43 # define our LLM
ExamplesUsingHuggingFaceOpenSourceModels 52
44 llm_predictor =LLMPredictor(llm =CustomLLM())
45
46 # Load the your data
47 documents =SimpleDirectoryReader( '../data_small').load_data()
48 index =GPTListIndex(documents, llm_predictor =llm_predictor,
49 prompt_helper =prompt_helper)
50 index =index.as_query_engine(llm_predictor =llm_predictor)
51
52 time2 =time.time()
53 print(f"Time to load model from disk: {time2 -time1} seconds.")
54
55 # Query and print response
56 response =index .query( "What is the definition of sport?")
57 print(response)
58
59 time3 =time.time()
60 print(f"Time for query/prediction: {time3 -time2} seconds.")
WhenrunningonmyM1MacBookProusingonlytheCPU(noGPUorNeuralEngineconfigura-
tion)wecanreadthemodelfromdiskquicklybutittakesawhiletoprocessqueries:
1$python hf_transformer_local.py
2INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total LL\
3M token usage: 0 tokens
4INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total em\
5bedding token usage: 0 tokens
6Time to load model from disk: 1.5303528308868408 seconds.
7INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 182 to\
8kens
9INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: \
10 0 tokens
11
12 "Sport" comes from the Old French desport meaning "leisure", with the oldest definit\
13 ion in English from around 1300 being "anything humans find amusing or entertaining"
14 .[4]
15 Time for query/prediction: 228.8184850215912 seconds.
EventhoughmyM1MacBookdoesfairlywellwhenIconfigureTensorFlowandPyTorchtousethe AppleSiliconGPUsandNeuralEngines,IusuallydomymodeldevelopmentusingGoogleColab.
Let’srerunthelastexampleonColab:
ExamplesUsingHuggingFaceOpenSourceModels 53
Usingastandard Colab GPU, the query/prediction time is much faster. Here isalink to my Colab
notebook4ifyouwouldprefertorunthisexampleonColabinsteadofonyourlaptop.
4https://colab.research.google.com/drive/1Ecg-
0iid3AD05zM4HgPXTVHcgkGxyi3q?usp=sharing Running Local LLMs Using Llama.cpp
and LangChain WesawanexampleattheendofthelastchapterrunningalocalLLM.Hereweusethe Llama.cpp1
project to runalocal model with LangChain. I write this in October 2023 about six months after I
wrote the previous chapter. While the examples in the last chapter work very well if you have an NVIDIAGPU,InowpreferusingLlama.cppbecauseitalsoworksverywellwithAppleSilicon. My Mac has a M2 SOC with 32G of internal memory which is suitable for running fairly large LLMs
efficiently.
Installing Llama.cpp with a Llama2-13b-orca Model NowwelookananapproachtorunLLMslocallyonyourowncomputers.
Amongthemanyopenandpublicmodels,IchoseHuggingFace’sLlama2-13b-orcamodelbecause
of its support for natural language processing tasks. The combination of Llama2-13b-orca with
the llama.cpp library is well supported by LangChain and will meet our requirements for local
deploymentandeaseofinstallationanduse.
Startbycloningthe llama.cpp projectandbuildingit:
1git clone https://github.com/ggerganov/llama.cpp.git
2make
3mkdir models Thengetamodelfilefrom https://huggingface.co/TheBloke/OpenAssistant-Llama2-13B-Orca-8K-
3319-GGUF andcopyto ./modelsdirectory:
1$ ls -lh models
28.6G openassistant-llama2-13b-orca-8k-3319.Q5_K_M.gguf It is not strictly required for you to clone Llama.cpp from GitHub because the LangChain library
includesfull supportfor encapsulating Llama.cppvia thellama-cpp-pythonlibrary. That said, you
can also run Llama.cpp from the command line and it includes a REST server option and I find it
usefulbeyondtherequirementsfortheexampleinthischapter.
Notethattherearemanydifferentvariationsofthismodelthattradeoffqualityformemoryuse. I
amusingoneofthelargermodels. Ifyouonlyhave8Gofmemorytryasmallermodel.
1https://github.com/ggerganov/llama.cpp RunningLocalLLMsUsingLlama.cppandLangChain 55
Python Example Thefollowingscriptisinthefile langchain-book-examples/llama.cpp/test.py andisderivedfrom
theLangChaindocumentation: https://python.langchain.com/docs/integrations/llms/llamacpp .
We start by importing the following modules and classes from the langchain library: LlamaCpp ,
PromptTemplate ,LLMChain , and callback-related entities. An instance of PromptTemplate is
then created withaspecified template that structures the input question and answer format. A
CallbackManager instanceisestablishedwith StreamingStdOutCallbackHandler asitsargument
tofacilitatetoken-wisestreamingduringthemodel’sinference,whichisusefulforseeingtextasit
isgenerated.
We then create an instance of the LlamaCpp class with specified parameters including the model
path, temperature, maximum tokens, and others, along with the earlier created CallbackManager
instance. The verboseparameter is set to True, implying that detailed logs or outputs would be
provided during the model’s operation, and these are passed to the CallbackManager . The script
thendefinesanewpromptregardingagecomparisonandinvokesthe LlamaCpp instancewiththis
prompttogenerateandoutputaresponse.
1from langchain.llms import LlamaCpp
2from langchain.prompts import PromptTemplate
3from langchain.chains import LLMChain
4from langchain.callbacks.manager import CallbackManager
5from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
6
7template ="""Question: {question}
8
9Answer: Let's work this out inastep by step way to be sure we have the right answe \
10 r."""
11
12 prompt =PromptTemplate(template =template, input_variables =["question"])
13
14 # Callbacks support token-wise streaming
15 callback_manager =CallbackManager([StreamingStdOutCallbackHandler()])
16
17 # Make sure the model path is correct for your system!
18 llm =LlamaCpp(
19 model_path ="/Users/markw/llama.cpp/models/openassistant-llama2-13b-orca-8k-3319. \
20 Q5_K_M.gguf",
21 temperature =0.75,
22 max_tokens =2000,
23 top_p=1,
24 callback_manager =callback_manager,
RunningLocalLLMsUsingLlama.cppandLangChain 56
25 verbose =True, # Verbose for callback manager
26 )
27
28 prompt ="""
29 Question: If Mary is 30 years old and Bob is 25, who is older and by how much?
30 """
31 print(llm(prompt))
Hereisexampleoutput(withoutputshortenedforbrevity):
1 $p test.py
2llama_model_loader: loaded meta data with 20key-value pairs and 363 tensors from /U\
3sers/markw/llama .cpp/models /openassistant -llama2 -13b-orca-8k-3319.Q5_K_M .gguf (versi
4on GGUF V2 (latest))
5
6My Answer: Mary isolder by 5years.
7A more complete answer should be: "To determine whether Mary or Bob is older, first \
8find the difference in their ages. This can be done by subtracting the smaller numbe
9r from the larger number .
10 For example, let 's say Mary is 30 years old and Bob is 25 years old. To find out who \
11 is older, we need to subtract Bob's age (25) from Mary's age (30). The answer is 5.
12 Therefore, Mary is5years older than Bob ."
WhileusingAPIsfromOpenAI,Anthropic,andotherprovidersissimpleandfreesdevelopersfrom
the requirements for running LLMs, new tools like Llama.cpp make it easier and less expensive to
run and deploy LLMs yourself. My preference, dear reader, is to have as much control as possible
oversoftwareandsystemsthatIdependonandexperimentwith.
Running Local LLMs Using Ollama We saw an example at the end of the last chapter running Llama.cpp1project to runalocal model
withLangChain. AsIwritethisinDecember2023InowmostoftenusetheOllamaapp(download,
documentation,andlistofsupportedmodelsat https://ollama.ai ). Ollamahasagoodcommandline
interfaceandalsorunsaRESTservicethattheexamplesinthischapteruse.
OllamaworksverywellwithAppleSilicon,systemswithanNVIDIAGPU,andhighendCPU-only
systems. My Mac has a M2 SOCwith 32G of internal memory which is suitable for running fairly
largeLLMsefficientlybutmostoftheexampleshererunfinewith16Gmemory.
Simple Use ofalocal Mistral Model Using LangChain WelookatasimpleexampleforaskingquestionsandtextcompletionsusingalocalMistralmodel.
TheOllamasupportinLangChainrequiresthatyourunOllamaasaserviceonyourlaptop:
1ollama serve Here I am using a Mistral model but I usually have several LLMs installed to experiment with, for
example:
1 $ollama list
2NAME ID SIZE MODIFIED
3everythinglm:13b bf6610a21b1e 7.4 GB 8 days ago
4llama2:13b b3f03629d9a6 7.4 GB 4 weeks ago
5llama2:latest fe938a131f40 3.8 GB 4 weeks ago
6llava:latest e4c3eb471fd8 4.5 GB 4 days ago
7meditron:7b ad11a6250f54 3.8 GB 8 days ago
8mistral:7b-instruct d364aa8d131e 4.1 GB 3 weeks ago
9mistral:instruct d364aa8d131e 4.1 GB 5 weeks ago
10 mistral:latest d364aa8d131e 4.1 GB 3 weeks ago
11 mixtral:8x7b-instruct-v0.1-q2_K 4278058671b6 15 GB 20 hours ago
12 openhermes2.5-mistral:latest ca4cd4e8a562 4.1 GB 3 weeks ago
13 orca2:13b a8dcfac3ac32 7.4 GB 8 days ago
14 samantha-mistral:latest f7c8c9be1da0 4.1 GB 8 days ago
15 wizard-vicuna-uncensored:30b 5a7102e25304 18 GB 4 weeks ago
16 yi:34b 5f8365d57cb8 19 GB 8 days ago Hereisthefile ollama_langchain/test.py :
1https://github.com/ggerganov/llama.cpp RunningLocalLLMsUsingOllama 58
1# requires "ollama serve" to be running inaterminal
2
3from langchain.llms import Ollama
4
5llm =Ollama(
6 model="mistral:7b-instruct",
7 verbose =False,
8)
9
10 s=llm("how much is 1 + 2?")
11 print(s)
12
13 s=llm("If Sam is 27, Mary is 42, and Jerry is 33, what are their age differences?")
14 print(s)
Hereistheoutput:
1$python test.py
21 + 2 = 3.
3
4To calculate their age differences, we simply subtract the younger person's age from\
5 the older person's age. Here are the calculations:
6- Sam is 27 years old, and Mary is 42 years old, so their age difference is 42 - 27 \
7= 15 years.
8- Mary is 42 years old, and Jerry is 33 years old, so their age difference is 42 - 3\
93 = 9 years.
10 - Jerry is 33 years old, and Sam is 27 years old, so their age difference is 33 - 27\
11 = 6 years.
Minimal Example Using Ollama with the Mistral Open Model for Retrieval Augmented Queries Against Local Documents The following listing of file ollama_langchain/rag_test.py demonstrates creatingapersistent
embeddings datastore and reusing it. In production, this example would be split into two separate Pythonscripts:
• Createapersistentembeddingsdatastorefromadirectoryoflocaldocuments.
• Openapersistedembeddingsdatastoreanduseitforqueriesagainstlocaldocuments.
Creatingalocalpersistentembeddingsdatastorefortheexampletextfilesin ../data/*.txt takesabout
90secondsonmyMacMini.
RunningLocalLLMsUsingOllama 59
1# requires "ollama serve" to be running in another terminal
2
3from langchain.llms import Ollama
4from langchain.embeddings.ollama import OllamaEmbeddings
5from langchain.chains import RetrievalQA
6
7from langchain.vectorstores import Chroma
8from langchain.text_splitter import RecursiveCharacterTextSplitter
9from langchain.document_loaders.directory import DirectoryLoader
10
11 # Create index (can be reused):
12
13 loader =DirectoryLoader( '../data', glob='**/*.txt')
14
15 data =loader .load()
16
17 text_splitter =RecursiveCharacterTextSplitter(
18 chunk_size =1000, chunk_overlap=100)
19 all_splits =text_splitter .split_documents(data)
20
21 persist_directory ='cache'
22
23 vectorstore =Chroma .from_documents(
24 documents =all_splits, embedding =OllamaEmbeddings(model ="mistral:instruct"),
25 persist_directory =persist_directory)
26
27 vectorstore .persist()
28
29 # Try reloading index from disk and using for search:
30
31 persist_directory ='cache'
32
33 vectorstore =Chroma(
34 persist_directory =persist_directory,
35 embedding_function =OllamaEmbeddings(model ="mistral:instruct")
36 )
37
38 llm =Ollama(base_url ="http://localhost:11434",
39 model="mistral:instruct",
40 verbose =False,
41 )
42
43 retriever =vectorstore .as_retriever()
RunningLocalLLMsUsingOllama 60
44
45 qa_chain =RetrievalQA .from_chain_type(
46 llm=llm,
47 chain_type ='stuff',
48 retriever =retriever,
49 verbose =True,)
50
51 while True:
52 query =input("Askaquestion: ")
53 response =qa_chain(query)
54 print(response[ 'result'])
Here is an example using this script. The first question uses the innate knowledge contained
in the Mistral-7B model while the second question uses the text files in the directory ../dataas
local documents. The test input file economics.txt has been edited to add the name ofafictional
economist. Iaddedthisdatatoshowthatthesecondquestionisansweredfromthelocaldocument
store.
1$python rag_test.py
2> Entering new RetrievalQA chain...
3
4> Finished chain.
5
611 + 2 = 13
7Askaquestion: Who says that economics is bullshit?
8
9
10 > Entering new RetrievalQA chain...
11
12 > Finished chain.
13
14 Pauli Blendergast, an economist who teaches at the University of Krampton Ohio, is k\
15 nown for saying that economics is bullshit.
W
rap Up for Running Local LLMs Using Ollama As I write this chapter in December 2023 most of my personal LLM experiments involve running
models locally on my Mac mini (or sometimes in Google Colab) even though models available
throughOpenAI,Anthropic,etc. APIsaremorecapable. IfindthattheOllamaprojectiscurrently
the easiest and most convenient way to run local models as REST services or embedded in Python
scriptsasinthetwoexampleshere.
Using Large Language Models to Write Recipes If you ask the ChatGPT web app to writearecipe usingauser supplied ingredient list andadescription it doesafairly good job at generating recipes. For the example in this chapter I am
takingadifferentapproach:
• Usetherecipeandingredientfilesfrommywebapp http://cookingspace.com tocreatecontext
text,givenauserpromptforarecipe.
• Treatthisasatextpredictionproblem.
• Formattheresponsefordisplay.
This approach has an advantage (for me!) that the generated recipes will be more similar to the
recipesIenjoycookingsincethecontextdatawillbederivedfrommyownrecipefiles.
Preparing Recipe Data IamusingtheJSONRecipefilesfrommywebapp http://cookingspace.com . ThefollowingPython
scriptconvertsmyJSONdatatotextdescriptions,oneperfile:
1import json
2
3def process_json (fpath):
4 with open(fpath, 'r') asf:
5 data =json.load(f)
6
7 for dindata:
8 with open(f"text_data/ {d['name']}.txt", 'w') asf:
9 f.write( "Recipe name: " +d['name'] +'\n\n')
10 f.write( "Number of servings: " +
11 str(d['num_served']) +'\n\n')
12 ingrediants =[" " +str(ii['amount']) +
13 ' ' +ii['units'] +' ' +
14 ii['description']
15 for iiind['ingredients']]
16 f.write( "Ingredients: \n" +
UsingLargeLanguageModelstoWriteRecipes 63
17 "\n".join(ingrediants) +'\n\n')
18 f.write( "Directions: " +
19 ' '.join(d[ 'directions']) +'\n')
20
21 if__name__ =="__main__":
22 process_json( 'data/vegetarian.json')
23 process_json( 'data/desert.json')
24 process_json( 'data/fish.json')
25 process_json( 'data/meat.json')
26 process_json( 'data/misc.json')
Hereisalistingofoneoftheshortergeneratedrecipefiles(i.e.,textrecipedataconvertedfromraw JSONrecipedatafrommyCookingSpace.comwebsite):
1Recipe name: Black Bean Dip
2
3Number of servings: 6
4
5Ingredients:
6 2 cup Refried Black Beans
7 1/4 cup Sour cream
8 1 teaspoon Ground cumin
9 1/2 cup Salsa
10
11 Directions: Use eitherafood processor oramixing bowl and hand mixer to make this\
12 appetizer. Blend the black beans and cumin for at least one minute until the mixtur
13 e is fairly smooth. Stir in salsa and sour cream and lightly mix. Serve immediately
14 or store in the refrigerator.
Ihavegenerated41individualrecipefilesthatwillbeusedfortheremainderofthischapter.
InthenextsectionwhenweuseaLLMtogeneratearecipe,thedirectionsarenumberedstepsand
theformattingisdifferentthanmyoriginalrecipedocumentfiles.
A Prediction Model Using the OpenAI
text-embedding-3-large Model Here we use the DirectoryLoader class that we have used in previous examples to load and then
createanembeddingindex.
Hereisthelistingforthescript recipe_generator.py :
UsingLargeLanguageModelstoWriteRecipes 64
1from langchain.text_splitter import CharacterTextSplitter
2from langchain.vectorstores import Chroma
3from langchain.embeddings import OpenAIEmbeddings
4from langchain_community.document_loaders import DirectoryLoader
5from langchain import OpenAI, VectorDBQA
6
7embeddings =OpenAIEmbeddings(model ="text-embedding-3-large")
8
9loader =DirectoryLoader( './text_data/', glob="**/*.txt")
10 documents =loader .load()
11 text_splitter =CharacterTextSplitter(chunk_size =2500,
12 chunk_overlap =0)
13
14 texts =text_splitter .split_documents(documents)
15
16 docsearch =Chroma .from_documents(texts, embeddings)
17
18 qa=VectorDBQA .from_chain_type(llm =OpenAI(temperature =0,
19 model_name =
20 "text-davinci-002"),
21 chain_type ="stuff",
22 vectorstore =docsearch)
23
24 def query(q):
25 print(f"\n\nRecipe creation request: {q}\n")
26 print(f"{qa.run(q) }\n\n")
27
28 query( "Createanew recipe using Broccoli and Chicken")
29 query( "Createarecipe using Beans, Rice, and Chicken")
Thisgeneratedtworecipes. Hereistheoutputforthefirstrequest:
1$python recipe_generator.py
2Running Chroma using direct local API.
3Using DuckDB in-memory for database. Data will be transient.
4
5Recipe creation request: Createanew recipe using both Broccoli and Chicken
6
7Recipe name: Broccoli and Chicken Teriyaki
8Number of servings: 4
9
10 Ingredients:
11 1 cup broccoli UsingLargeLanguageModelstoWriteRecipes 65
12 1 pound chicken meat
13 2 tablespoons soy sauce
14 1 tablespoon honey
15 1 tablespoon vegetable oil
16 1 clove garlic, minced
17 1 teaspoon rice vinegar
18
19 Directions:
20
21 1. Inalarge bowl, whisk together soy sauce, honey, vegetable oil, garlic, and rice\
22 vinegar.
23 2. Cut the broccoli into small florets. Add the broccoli and chicken to the bowl and\
24 toss to coat.
25 3. Preheatagrill or grill pan over medium-high heat.
26 4. Grill the chicken and broccoli for 5-7 minutes per side, or until the chicken is \
27 cooked through and the broccoli is slightly charred.
28 5. Serve immediately.
IfyouexaminethetextrecipefilesIindexedyouseethatthepredictionmodelmergedinformation
from multiple training data recipes while creating new original text for directions that is loosely
basedonthedirectionsthatIwroteandinformationencodedintheOpenAItext-davinci-002model.
Hereistheoutputforthesecondrequest:
1Recipe creation request: Createarecipe using Beans, Rice, and Chicken
2
3Recipe name: Beans and Rice with Chicken
4Number of servings: 4
5Ingredients:
61 cup white rice
71 cup black beans
81 chicken breast, cooked and shredded
91/2 teaspoon cumin
10 1/2 teaspoon chili powder
11 1/4 teaspoon salt
12 1/4 teaspoon black pepper
13 1 tablespoon olive oil
14 1/2 cup salsa
15 1/4 cup cilantro, chopped
16
17 Directions:
18 1. Cook rice according to package instructions.
19 2. Inamedium bowl, combine black beans, chicken, cumin, chili powder, salt, and bl\
UsingLargeLanguageModelstoWriteRecipes 66
20 ack pepper.
21 3. Heat olive oil inalarge skillet over medium heat. Add the bean mixture and cook\
22 until heated through, about 5 minutes.
23 4. Stir in salsa and cilantro. Serve over cooked rice.
Cooking Recipe Generation Wrap Up Cooking is one of my favorite activities (in addition to hiking, kayaking, and playingavariety of
musicalinstruments). Ioriginallywrotethe CookingSpace.com1webapptoscratchapersonalitch:
due toamedical issue I had to closely monitor and regulate my vitamin K intake. I used the US
Government’sUSDANutritionDatabasetoestimatetheamountsofvitaminsandnutrientsinsome
recipesthatIuse.
WhenIwantedtoexperimentwithgenerativemodels,backedbymypersonalrecipedata,tocreate
recipes,havingavailablerecipedatafrommypreviousprojectaswellastoolslikeOpenAIAPIsand LangChainmadethisexperimentsimpletosetupandrun. Itisacommonthemeinthisbookthat
itisnowrelativelyeasytocreatepersonalprojectsbasedonourdataandourinterests.
1http://cookingspace.com LangChain Agents LangChainagenttoolsactasagluetomapnaturallanguagehumaninputintodifferentsequences
of actions. We are effectively using the real world knowledge in the text used to train LLMs to act
asareasoningagent.
TheLangChainAgentsDocumentation1provideseverythingyouneedtogetstarted. Herewewill
diveabitdeeperintousinglocalPythonscriptsinagentsandlookataninterestingexampleusing SPARQLqueriesandthepublicDBPediaKnowledgeBase. Wewillconcentrateonjustafewtopics:
• UnderstandingwhatLangChaintoolsareandusingpre-builttools.
• Get an overview of React reasoning. You should bookmark the original paper ReAct:
Synergizing Reasoning and Acting in Language Models2for reference. This paper inspired
designandimplementationoftheagenttoolcodeinLangChain.
• Writing custom functions for OpenAI: how to writeacustom tool. We will writeatool that
usesSPARQLqueriestotheDBPediapublicKnowledgeGraph.
Overview of LangChain Tools Aswehavecoveredwithmanyexamplesinthisbook,LangChainisaframeworkthatprovidestools
forbuildingLLM-poweredapplications.
Here we look at using built in LangChain agent tools, understand reactive agents, and end the
chapterwithacustomtoolagentapplication.
LangChaintoolsareinterfacesthatanagentcanusetointeractwiththeworld. Theycanbegeneric
utilities(e.g. search),otherchains,orevenotheragents. TheinterfaceAPIofatoolhasasingletext
inputandasingletextoutput,andincludesanameanddescriptionthatcommunicatetothemodel
whatthetooldoesandwhentouseit.
Sometoolscanbeusedas-isandsometools(e.g. chains,agents)mayrequireabaseLLMtouseto
initializethem. Inthatcase,youcanpassinanLLMaswell:
1https://python.langchain.com/docs/modules/agents.html
2https://react-
lm.github.io/
LangChainAgents 68
1from langchain.agents import load_tools
2tool_names =[...]
3llm = ...
4tools =load_tools(tool_names, llm =llm).
Toimplementyourowntool,youcansubclasstheToolclassandimplementthe _callmethod. The
_callmethod is called with the input text and should return the output text. The Tool superclass
implementsthecallmethod,whichtakescareofcallingtheright CallbackManager methodsbefore
andaftercallingyour _callmethod. Whenanerroroccurs,the _callmethodshouldwhenpossible
returnastring representing an error, rather than throwing an error. This allows the error to be
passedtotheLLMandtheLLMcandecidehowtohandleit.
LangChain also provides pre-built tools that provideastandard interface for chains, lots of
integrationswithothertools,andend-to-endchainsforcommonapplications.
In summary, LangChain tools are interfaces that agents can use to interact with the world. They
can be generic utilities or other chains or agents. Here isalist of some of the available LangChain
agenttools:
• AWSLambda-AwrapperaroundtheAWSLambdaAPI,invokedviatheAmazonWebServices Node.js SDK. Useful for invoking server less functions with any behavior which you need to
providetoanAgent.
• BingSerpAPI-AwrapperaroundtheBingSearchAPI.
• BraveSearch-AwrapperaroundtheBraveSearchAPI.
• Calculator-Usefulforgettingtheresultofamathexpression.
• GoogleCustomSearch-AwrapperaroundtheGoogleCustomSearchAPI.
• IFTTTWebHook-AwrapperaroundtheIFTTTWeb-hookAPI.
• OpenAI-AwrapperaroundtheOpenAIAPI.
• OpenWeatherMap-AwrapperaroundtheOpenWeatherMapAPI.
• Random-Usefulforgeneratingrandomnumbers,strings,andothervalues.
• Wikipedia-AwrapperaroundtheWikipediaAPI.
• WolframAlpha-AwrapperaroundtheWolframAlphaAPI.
Overview of ReAct Library for Implementing Reading
in LMS Applications Mostofthematerialinthissectionisreferencedfromthepaper ReAct: SynergizingReasoningand Acting in Language Models3. The ReAct framework attempts to solve the basic problem of getting LLMs to accurately perform tasks. We want an LLM to understand us and actually do what we
want. I takeadifferent but similar approach for an example in my book Safe For Humans AI A
3https://react-
lm.github.io/
LangChainAgents 69
“humans-first”approachtodesigningandbuildingAIsystems4(linkforreadingfreeonline)where I use two different LLMs, one to generate answers questions and another LLM to judge how well
thefirst modeldid. Thatexampleisfairlyad-hocbecauseIwasexperimentingwithanidea. Here
wedomuchthesamethingusingapre-builtframework.
ReActisanextensionoftheideathatLLMsperformbetterwhenweasknotonlyforananswerbut
also for the reasoning steps to generate an answer. The authors of the ReAct paper refer to these
reasoningstepsas“reasoningtraces.”
Anotherapproachto usingLLMs inapplications isto askdirectionsfor actionsfromanLLM, take
thoseactions,andreporttheresultsoftheactionsbacktotheLLM.Thisactionloopcanberepeated.
TheReActpapercombinesreasoningtracesandactionloops. Toparaphrasethepaper:
Large language models (LLMs) have shown impressive abilities in understanding language and
making decisions. However, their capabilities for reasoning and taking action has been new work
with some promising results. Here we look at using LLMs to generate both reasoning traces and
task-specificactionstogether. Thisallowsforbettersynergybetweenthetwo: reasoningtraceshelp
themodelcreateandupdateactionplans,whileactionsletitgathermoreinformationfromexternal
sources. For question answering and fact verification tasks, ReAct avoids errors by usingasimple Wikipedia API and generates human-like solutions. On interactive decision making tasks, ReAct
hashighersuccessratescomparedtoothermethods,evenwithlimitedexamples.
A ReAct prompt consists of example solutions to tasks, including reasoning traces, actions, and
observations of the environment. ReAct prompting is easy to design and achieves excellent
performanceonvarioustasks,fromansweringquestionstoonlineshopping.
The ReAct paper serves as the basis for the design and implementation of support for LangChain
agenttools. Welookatanexampleapplicationusingacustomtoolinthenextsection.
LangChain Agent Tool Example Using DBPedia SPARQL
Queries BeforewelookatthetheLangChainagentcustomtoolcode,let’slookatsomeutilitycodefrommy Colab notebook Question Answering Example using DBPedia and SPARQL5(link to shared Colab
notebook). Iextractedjustthecodeweneedintothefile QA.py(editedtofitpagewidth):
4https://leanpub.com/safe-
for-humans-AI/read
5https://colab.research.google.com/drive/1FX-0eizj2vayXsqfSB2ONuJYG8BaYpGO?usp=sharing LangChainAgents 70
1# Copyright 2021-2023 Mark Watson
2
3import spacy
4
5nlp_model =spacy.load("en_core_web_sm")
6
7from SPARQLWrapper import SPARQLWrapper, JSON
8
9sparql =SPARQLWrapper( "http://dbpedia.org/sparql")
10
11 def query(query):
12 sparql .setQuery(query)
13 sparql .setReturnFormat(JSON)
14 return sparql .query() .convert()[ "results"]["bindings"]
15
16 def entities_in_text (s):
17 doc =nlp_model(s)
18 ret ={}
19 for [ename, etype] in[[entity .text, entity.label_] for entity indoc.ents]:
20 ifetype inret:
21 ret[etype] =ret[etype] +[ename]
22 else:
23 ret[etype] =[ename]
24 return ret
25
26 # NOTE: !! note "{{" .. "}}" double curly brackets: this is to escape for Python Str\
27 ing format method:
28
29 sparql_query_template ="""
30 select distinct ?s ?comment where {{
31 ?s
32 <http://www.w3.org/2000/01/rdf-schema#label>
33 '{name} '@en .
34 ?s
35 <http://www.w3.org/2000/01/rdf-schema#comment>
36 ?comment .
37 FILTER (lang(?comment) = 'en') .
38 ?s
39 <http://www.w3.org/1999/02/22-rdf-syntax-ns#type>
40 {dbpedia_type} .
41 }} limit 15
42 """
43
LangChainAgents 71
44 def dbpedia_get_entities_by_name (name, dbpedia_type):
45 print(f"{name=} {dbpedia_type =}")
46 s_query =\
47 sparql_query_template .format(
48 name=name,
49 dbpedia_type =dbpedia_type
50 )
51 print(s_query)
52 results =query(s_query)
53 return results
54
55 entity_type_to_type_uri ={
56 "PERSON": "<http://dbpedia.org/ontology/Person>",
57 "GPE": "<http://dbpedia.org/ontology/Place>",
58 "ORG": "<http://dbpedia.org/ontology/Organisation>",
59 }
60
61 def get_context_text (query_text):
62 entities =entities_in_text(query_text)
63
64 def helper (entity_type):
65 ret =""
66 ifentity_type inentities:
67 for hname inentities[entity_type]:
68 results =dbpedia_get_entities_by_name(
69 hname,
70 entity_type_to_type_uri[entity_type]
71 )
72 for result inresults:
73 ret +=ret +\
74 result[ "comment"]["value"] +\
75 " . "
76 return ret
77
78 context_text =helper( "PERSON") +\
79 helper( "ORG") +\
80 helper( "GPE")
81 #print("\ncontext text:\n", context_text, "\n")
82 return context_text WeusethespaCylibraryandasmallspaCyNLPmodelthatwesetupinlines3-5.
I have written two books dedicated to SPARQL queries as well as providing SPARQL overviews
and examples in my Haskell, Common Lisp, and Hy Language books and I am not going to LangChainAgents 72
repeat thatdiscusionhere. Youcan readthesemantic webandSPARQLmaterialfreeonline using
[https://leanpub.com/lovinglisp/read#leanpub-auto-semantic-web-and-linked-data](thislink).
Lines7-14containPythoncodeforqueryingDBPedia.
Lines16-25usethespaCylibrarytoidentifyboththeentitiesinauser’squeryaswellastheentity
type.
We define a SPARQL query template in lines 30-43 that uses Python F string variables nameand
dbpedia_type .
Thefunction dbpedia_get_entities_by_name definedinlines45-54replacesvariableswithvalues
intheSPARQLquerytemplateandmakesaSPARQLquerytoDBPedia.
Thefunction get_context_text whichisthefunctioninthisfilewewilldirectlycalllaterisdefined
in lines 65-83. We get entities and entity types in line 63. We define an interbal helper function in
lines65-77thatwewillcallonceforeachofthreeDBPediaentitytypesthatweuseinthisexample
(people,organizations. andorganizations).
HereweusespaCysoinstallthelibraryandasmallNLPmodel:
1pip install import spacy
2python -m spacy download en_core_web_sm The agent custom tool example is short so I list the source file custom_func_dbpedia.py first and
thenwewilldiveintothecode(editedtofitpagewidth):
1from QAimport get_context_text
2
3def get_context_data (query_text):
4 """
5 Method to get context text for entities from
6 DBPedia using SPARQL query
7 """
8
9 query_text_data =get_context_text(query_text)
10 return {"context_text": query_text_data}
11
12 ## Custom function example using DBPedia
13
14 from typing import Type
15 from pydantic import BaseModel, Field
16 from langchain.tools import BaseTool
17
18 class GetContextTextFromDbPediaInput (BaseModel):
19 """Inputs for get_context_data"""
LangChainAgents 73
20
21 query_text: str =\
22 Field(
23 description ="query_text user supplied query text"
24 )
25
26 class GetContextTextFromDbPediaTool (BaseTool):
27 name ="get_context_data"
28 description =
29 """
30 Useful when you want to makeaquery and get
31 context text from DBPedia. You should enter
32 and text containing entity names.
33 """
34 args_schema: Type[BaseModel] =\
35 GetContextTextFromDbPediaInput
36
37 def _run(self, query_text: str):
38 text =get_context_data(query_text)
39 return text
40
41 def _arun(self, query_text: str):
42 raise NotImplementedError
43 (
44 "get_context_data does not support async"
45 )
46
47 ## Create agent
48
49 from langchain.agents import AgentType
50 from langchain.chat_models import ChatOpenAI
51 from langchain.agents import initialize_agent
52
53 llm =ChatOpenAI(model ="gpt-3.5-turbo-0613",
54 temperature =0)
55
56 tools =[GetContextTextFromDbPediaTool()]
57
58 agent =initialize_agent(tools, llm,
59 agent=AgentType .OPENAI_FUNCTIONS,
60 verbose =True)
61
62 ## Run agent LangChainAgents 74
63
64 agent.run(
65 """
66 What country is Berlin in and what other
67 information about the city do you have?
68 """
69 )
The class GetContextTextFromDbPediaInput defined in lines 18-24 definesatool input variable
with an English language description for the variable that the LLM can use. The class GetCon-
textTextFromDbPediaTool defined in lines 26-45 defines the tool name, a description for the use
of an LLM, and the definition of the required methon _run. Methon _runuses the utility finction
get_context_data definedinthesourcefile QA.py.
We define a GPT-3.5 model in lines 53-54. Out example only uses one tool (our custom tool). We
definethetoolslistinline56andsetuptheagentinlines58-60.
Theexampleoutputis(editedtofitpagewidth):
1>Entering new AgentExecutor chain ...
2
3Invoking: `get_context_data `with `{'query_text':
4 'Berlin'}`
5
6name='Berlin'
7dbpedia_type ='<http://dbpedia.org/ontology/Place>'
8
9 select distinct ?s?comment where {
10 ?s
11 <http://www.w3.org/2000/01/rdf-schema #label>
12 'Berlin'@en .
13 ?s
14 <http://www.w3.org/2000/01/rdf-schema #comment>
15 ?comment .
16 FILTER (lang(?comment) ='en') .
17 ?s
18 <http://www.w3.org/1999/02/22-rdf-syntax -ns#type>
19 <http://dbpedia .org/ontology /Place> .
20 } limit 15
21
22 {'context_text': "Berlin (/b￿￿r￿l￿n/ bur-LIN, German: [b￿￿￿li￿n]) is the capital and \
23 largest city of Germany by both area and population. Its 3.6 million inhabitants ma
24 ke it the European Union 's most populous city, according to population within city l
25 imits. One of Germany's sixteen constituent states, Berlin is surrounded by the Stat LangChainAgents 75
26 e of Brandenburg and contiguous with Potsdam, Brandenburg 's capital. Berlin's urban
27 area, which hasapopulation of around 4.5 million, isthe second most populous urba
28 n area inGermany after the Ruhr .The Berlin-Brandenburg capital region has around 6
29 .2million inhabitants and isGermany 's third-largest metropolitan region after the
30 Rhine-Ruhr and Rhine-Main regions. . "}
31
32 Berlin isthe capital and largest city of Germany .Itislocated inthe northeastern\
33 part of the country .Berlin hasapopulation of approximately 3.6 million people, m
34 aking it the most populous city inthe European Union .Itissurrounded by the State
35 of Brandenburg and iscontiguous with Potsdam, the capital of Brandenburg .The urba
36 n area of Berlin hasapopulation of around 4.5 million, making it the second most p
37 opulous urban area inGermany after the Ruhr .The Berlin-Brandenburg capital region
38 hasapopulation of approximately 6.2 million, making it Germany 's third-largest met
39 ropolitan region after the Rhine -Ruhr and Rhine-Main regions.
40
41 >Finished chain.
LangChain Agent Tools Wrap Up Writingcustomagenttoolsisagreatwaytorevisittheimplementationofexistingapplicationsand
improvethemwiththerealworldknowledgeandreasoningabilitiesofLLMs. Bothforpracticein
effectively using LLMs in your applications and also to extend your personal libraries and tools, I
suggestthatyoulookoveryouexistingprojectswithaneyeforeitherimprovingthemusingLLMs
orrefactoringthemintoreusableagenttoolsforyourfutureprojects.
Mor
e Useful Libraries for Working
with Unstructured Text Data HerewelookatexamplesusingtwolibrariesthatIfindusefulformywork: EmbedChainandKor.
EmbedChain Wrapper for LangChain Simplifies Application Development Taranjeet Singh developedavery nice wrapper library EmbedChain https://github.com/
embedchain/embedchain that simplifies writing “query your own data” applications by choosing
gooddefaultsfortheLangChainlibrary.
I will showone simple examplethat I run on my laptop to searchthe contents of all of the books I
havewrittenaswellasalargenumberofresearchpapers. YoucanfindmyexampleintheGitHub
repository for this book in the directory langchain-book-examples/embedchain_test . As usual,
youwillneedanOpenAIAPIaccountandsettheenvironmentvariable OPENAI_API_KEY tothe
valueofyourkey.
IhavecopiedPDF filesfor all ofthis contentto the directory ~/dataonmy laptop. It takesa short
while to buildalocal vector embedding data store so I use two Python scripts. The first script
process_pdfs.py thatisshownhere:
1# reference: https://github.com/embedchain/embedchain
2
3from embedchain import App
4import os
5
6test_chat =App()
7
8my_books_dir ="/Users/mark/data/"
9
10 for filename inos.listdir(my_books_dir):
11 iffilename .endswith( '.pdf'):
12 print("processing filename:", filename)
13 test_chat .add("pdf_file",
14 os.path.join(my_books_dir,
15 filename))
HereisademoPythonscript app.pythatmakesthreequeries:
MoreUsefulLibrariesforWorkingwithUnstructuredTextData 77
1from embedchain import App
2
3test_chat =App()
4
5def test(q):
6 print(q)
7 print(test_chat .query(q), "\n")
8
9test("How can I iterate overalist in Haskell?")
10 test("How can I edit my Common Lisp files?")
11 test("How can I scrapeawebsite using Common Lisp?")
Theoutputlookslike:
1$python app.py
2How can I iterate overalist in Haskell?
3To iterate overalist in Haskell, you can use recursion or higher-order functions l\
4ike `map` or `foldl`.
5
6How can I edit my Common Lisp files?
7To edit Common Lisp files, you can use Emacs with the Lisp editing mode. By setting \
8the default auto-mode-alist in Emacs, whenever you openafile with the extensions "
9.lisp", ".lsp", or ".cl", Emacs will automatically use the Lisp editing mode. You ca
10 n search for an "Emacs tutorial" online to learn how to use the basic Emacs editing
11 commands.
12
13 How can I scrapeawebsite using Common Lisp?
14 One way to scrapeawebsite using Common Lisp is to use the Drakma library. Paul Nat\
15 han has writtenalibrary using Drakma called web-trotter.lisp, which is available u
16 nder the AGPL license at articulate-lisp.com/src/web-trotter.lisp. This library can
17 beagood starting point for your scraping project. Additionally, you can use the wg
18 et utility to make local copies ofawebsite. The command "wget -m -w 2 http:/knowle
19 dgebooks.com/" can be used to mirrorasite withatwo-second delay between HTTP req
20 uests for resources. The option "-m" indicates to recursively follow all links on th
21 e website, and the option "-w 2" addsatwo-second delay between requests. Another o
22 ption, "wget -mk -w 2 http:/knowledgebooks.com/", converts URI references to local f
23 ile references on your local mirror. Concatenating all web pages into one file can a
24 lso beauseful trick.
MoreUsefulLibrariesforWorkingwithUnstructuredTextData 78
Kor Library The Kor library was written by Eugene Yurtsev. Kor is useful for using LLMs to extract structured
datafromunstructuredtext. KorworksbygeneratingappropriateprompttexttoexplaintoGPT-3.5
whatinformationtoextractandaddinginthetexttobeprocessed.
TheGitHubrepositoryforKor1isunderactivedevelopmentsopleasechecktheprojectforupdates.
Hereisthe documentation2.
Forthefollowingexample,ImodifiedanexampleintheKordocumentationforextractingdatesin
text.
1" From documentation: https://eyurtsev.github.io/kor/"
2
3from kor.extraction import create_extraction_chain
4from kor.nodes import Object, Text, Number
5from langchain.chat_models import ChatOpenAI
6from pprint import pprint
7import warnings ; warnings.filterwarnings( 'ignore')
8
9llm =ChatOpenAI(
10 model_name ="gpt-3.5-turbo",
11 temperature =0,
12 max_tokens =2000,
13 frequency_penalty =0,
14 presence_penalty =0,
15 top_p=1.0,
16 )
17
18 schema =Object(
19 id="date",
20 description =(
21 "Any dates found in the text. Should be output in the format:"
22 " January 12, 2023"
23 ),
24 attributes =[
25 Text(id ="month",
26 description ="The month of the date",
27 examples =[("Someone met me on December 21, 1995",
28 "Let's meet up on January 12, 2023 and discuss our yearly bu \
29 dget")])
1https://github.com/eyurtsev/kor
2https://eyurtsev.github.io/kor/
MoreUsefulLibrariesforWorkingwithUnstructuredTextData 79
30 ],
31 )
32
33 chain =create_extraction_chain(llm, schema, encoder_or_encoder_class ='json')
34
35
36 pred =chain.predict_and_parse(text ="I will go to California May 1, 2024")['data']
37 print("* month mentioned in text=", pred)
Sampleoutput:
1$python dates.py
2* month mentioned in text= {'date': {'month': 'May'}}
Kor isalibrary focused on extracting data from text. You can get the same effects by writing for
ownpromptsmanuallyforGPTstyleLLMsbutusingTorcansavedevelopmenttime.
Book Wrap Up Thisbookhasbeenfuntowritebutithasalsosomewhatfrustrating.
It was fun because I have never been as excited by new technology as I have by LLMs and utility
softwarelikeLangChainandLlamaIndexforbuildingpersonalizedapplications.
This book was frustrating in the sense that it is now so very easy to build applications that justafew years would have been impossible to write. Usually when I write books I have two criteria:
I only write about things that I am personally interested in and use, and I also hope to figure out
non-obvious edge cases and make easier for my readers to use new tech. Here my frustration is
writingaboutsomethingthatitisincreasinglysimpletodosoIfeellikemyvalueisdiminished.
AllthatsaidIhope,dearreader,thatyoufoundthisbooktobeworthyourtimereading.
What am I going to do next? Although I am not fond of programming in JavaScript (although I
findTypeScripttobesomewhatbetter),Iwanttoexplorethepossibilitiesofwritinganopensource Persistent Storage Web App Personal Knowledge Base Management System. I might get pushback
onthisbutIwouldprobablymakeitAppleSafarispecificsoIcanuseApple’sCloudKitJStomake
itsuseseamlessacrossmacOS,iPadOS,andiOS.IfIgettherightkindoffeedbackonsocialmedia Imightwriteabookaroundthisproject.
Thankyouforreadingmybook!
Bestregards,MarkWatson