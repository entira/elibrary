# eLibrary - PDF Knowledge Base with RAG

Advanced PDF processing system that converts document libraries into searchable video-based indexes using Memvid technology and Retrieval Augmented Generation (RAG).

## üèóÔ∏è System Architecture

### Current Implementation
Advanced processing pipeline with enhanced metadata extraction and cross-page context preservation:

- **Current Processor**: Token-based sliding window chunking (500 tokens, 15% overlap) with detailed page metadata

### Future Architecture Overview

```mermaid
graph TB
    subgraph "Input Layer"
        PDF[üìÑ PDF Documents]
        CONFIG[‚öôÔ∏è Configuration]
    end
    
    subgraph "Processing Pipeline"
        PROC[üîß PDF Processor]
        ENC[üîê Encrypted QR Encoder]
        VID[üé• Video Generator]
    end
    
    subgraph "Storage Layer"
        CDN[‚òÅÔ∏è CDN/S3 Storage]
        LOCAL[üíæ Local Cache]
    end
    
    subgraph "Security Layer"
        WEB3[üåê Web3 Key Derivation]
        TOR[üï∏Ô∏è Tor Network]
        ENCRYPT[üîí AES-256-GCM]
    end
    
    subgraph "Access Layer"
        WEBAPP[üåç Web3 + Tor App]
        MCP[ü§ñ MCP Server]
        API[üì° REST API]
    end
    
    subgraph "Client Applications"
        CLAUDE[üß† Claude Desktop]
        VSCODE[üìù VS Code Extension]
        CLI[‚å®Ô∏è CLI Tools]
        BROWSER[üåê Anonymous Browser]
    end
    
    %% Processing Flow
    PDF --> PROC
    PROC --> ENC
    ENC --> VID
    
    %% Storage Flow  
    VID --> CDN
    VID --> LOCAL
    
    %% Security Integration
    WEB3 --> ENCRYPT
    TOR --> WEBAPP
    ENCRYPT --> ENC
    
    %% Access Flow
    CDN --> WEBAPP
    CDN --> MCP
    CDN --> API
    
    %% Client Integration
    MCP --> CLAUDE
    MCP --> VSCODE
    MCP --> CLI
    WEBAPP --> BROWSER
    
    %% Styling
    classDef input fill:#e1f5fe
    classDef processing fill:#f3e5f5
    classDef storage fill:#e8f5e8
    classDef security fill:#fff3e0
    classDef access fill:#fce4ec
    classDef client fill:#f1f8e9
    
    class PDF,CONFIG input
    class PROC,ENC,VID processing
    class CDN,LOCAL storage
    class WEB3,TOR,ENCRYPT security
    class WEBAPP,MCP,API access
    class CLAUDE,VSCODE,CLI,BROWSER client
```

### Detailed Component Architecture

```mermaid
graph LR
    subgraph "PDF Processing Pipeline"
        A[üìÑ Raw PDF] --> B[üîß PyMuPDF Extraction]
        B --> C[üßπ Text Cleaning]
        C --> D[üî¢ Token-based Chunking]
        D --> E[üìä Metadata Extraction]
        E --> F[üîê AES Encryption]
        F --> G[üì± QR Generation]
        G --> H[üé• Video Assembly]
    end
    
    subgraph "Web3 Security Flow"
        I[üîë Wallet Private Key] --> J[‚ö° Key Derivation]
        J --> K[üîí Encryption Key]
        K --> F
        L[üï∏Ô∏è Tor Browser] --> M[üåê .onion Access]
        M --> N[üîì Client Decryption]
    end
    
    subgraph "CDN Distribution"
        H --> O[‚òÅÔ∏è S3 Upload]
        O --> P[üåç CloudFront CDN]
        P --> Q[üì° HTTP Range Requests]
        Q --> R[üéØ Frame-level Access]
    end
    
    subgraph "MCP Integration"
        S[ü§ñ MCP Server] --> T[üîç Encrypted Search]
        T --> U[üß† AI Assistant]
        U --> V[üí¨ Enhanced Responses]
        V --> W[üìö Citation Integration]
    end
```

## üéØ Current Features

- **High-Quality PDF Processing**: PyMuPDF-based extraction that eliminates encoding issues
- **Token-Based Chunking**: 500-token sliding window chunks with 15% overlap for optimal RAG performance
- **Semantic Boundary Preservation**: Intelligent sentence boundary detection prevents fragmented chunks
- **Issue #2 Resolution**: Fixes "Gener ative AI", null bytes, and split word problems
- **AI Metadata Extraction**: Ollama-powered extraction of titles, authors, publishers, years, DOI/ISBN
- **Video-based Indexing**: QR-encoded text chunks in video frames for efficient storage
- **Cross-page Context**: Enhanced processor preserves context between pages
- **RAG Integration**: Ready for Retrieval Augmented Generation workflows
- **Interactive Chat**: Query your PDF library with natural language and source citations
- **Accurate Page References**: Real PDF page numbers for precise citation tracking
- **Enhanced Library Display**: Complete metadata including publishers, DOI/ISBN information

## üöÄ Planned Features & Roadmap

### üìç Phase 1: Cloud Infrastructure (Q1 2025)

#### CDN/S3 Streaming Support ([Issue #11](https://github.com/entira/elibrary/issues/11))
- **HTTP Range Requests**: Stream video frames on-demand from CDN
- **Multi-CDN Support**: AWS S3/CloudFront, generic HTTP servers
- **Authentication**: Bearer tokens, Basic Auth, IAM credentials
- **Performance**: 95%+ bandwidth reduction vs full video download
- **Scalability**: Unlimited concurrent users with shared CDN storage

**Implementation:**
```python
# Stream-enabled chat interface
chat = StreamingMemvidChat(
    video_url="https://cdn.example.com/library.mp4",
    index_url="https://cdn.example.com/library_index.json",
    auth_headers={"Authorization": "Bearer token"}
)
```

### üîí Phase 2: Security & Encryption (Q2 2025)

#### QR Code Content Encryption ([Issue #12](https://github.com/entira/elibrary/issues/12))
- **AES-256-GCM Encryption**: Military-grade encryption for sensitive content
- **Zero-Knowledge Server**: Server cannot decrypt user content
- **Public Metadata**: Keep indexing fast while content stays encrypted
- **Key Management**: PBKDF2 key derivation, environment-based keys
- **Streaming Compatible**: Video structure preserved for CDN delivery

**Security Model:**
```mermaid
graph TD
    A[üìÑ Original Text] --> B[üîê AES-256-GCM]
    B --> C[üì± Encrypted QR]
    C --> D[üé• Video Frame]
    
    E[üîë User Key] --> F[üîì Client Decryption]
    F --> G[üìñ Readable Content]
    
    H[üåç Public CDN] --> I[‚ùå Cannot Decrypt]
    D --> H
```

### üï∏Ô∏è Phase 3: Anonymous Access (Q3 2025)

#### Web3 + Tor Application ([Issue #13](https://github.com/entira/elibrary/issues/13))
- **Tor Hidden Service**: Anonymous .onion domain access
- **Web3 Authentication**: Crypto wallet-based key derivation
- **Client-Side Decryption**: Browser-based cryptography (Web Crypto API)
- **No External Dependencies**: Fully self-contained for Tor compatibility
- **Privacy-First Design**: Zero tracking, no cookies, no analytics

**Web3 Integration:**
```javascript
// Browser-based key derivation
class Web3KeyManager {
    async deriveEncryptionKey(privateKey, libraryId) {
        const combined = `${privateKey}:${libraryId}:memvid`;
        // PBKDF2 key derivation in browser
        return await crypto.subtle.deriveBits({
            name: 'PBKDF2',
            salt: encoder.encode('memvid-web3-salt'),
            iterations: 100000,
            hash: 'SHA-256'
        }, keyMaterial, 256);
    }
}
```

### ü§ñ Phase 4: AI Integration (Q4 2025)

#### MCP Server for Documentation Q&A ([Issue #14](https://github.com/entira/elibrary/issues/14))
- **Model Context Protocol**: Standard integration with Claude and other AI assistants
- **Technical Documentation Focus**: Code examples, API references, tutorials
- **IDE Integration**: VS Code extensions, Claude Desktop plugins
- **Real-time Q&A**: Fast responses for development workflows
- **Enhanced Citations**: Precise source references with line numbers

**MCP Tools:**
```python
# MCP tool examples
@mcp_server.tool("search_docs")
async def search_docs(query: str, library: str, top_k: int = 5):
    """Search technical documentation with encrypted content"""
    
@mcp_server.tool("answer_question") 
async def answer_question(question: str, library: str):
    """Answer questions using encrypted docs with citations"""
    
@mcp_server.tool("explain_code")
async def explain_code(code_snippet: str, language: str):
    """Explain code using relevant documentation"""
```

## üéØ Use Case Evolution

### Current: Basic PDF Q&A
```bash
# Simple local chat
python3 pdf_chat.py
ü§î You: How to make better podcasts?
ü§ñ Answer with citations...
```

### Phase 1: Scalable Cloud Deployment
```bash
# Multi-user cloud-based system
chat = StreamingMemvidChat("https://cdn.company.com/docs.mp4")
# Serves unlimited users from shared CDN
```

### Phase 2: Secure Enterprise
```bash
# Encrypted content for sensitive documents
chat = EncryptedMemvidChat(video_url, encryption_key)
# Zero-knowledge: server never sees decrypted content
```

### Phase 3: Anonymous Research
```bash
# Privacy-focused research via Tor
# Access via: abc123def456.onion
# Web3 wallet authentication
# Fully anonymous document analysis
```

### Phase 4: AI-Augmented Development
```bash
# VS Code integration
# Hover over function ‚Üí instant documentation
# Claude Desktop enhanced with domain knowledge
# Real-time code explanations with citations
```

## üìä Performance & Security Matrix

| Feature | Scalability | Security | Privacy | Performance |
|---------|-------------|----------|---------|-------------|
| **Current Local** | ‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **CDN Streaming** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **QR Encryption** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Web3 + Tor** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **MCP Integration** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

## üîó Integration Ecosystem

### Development Tools
- **VS Code Extension**: Inline documentation, hover help
- **Claude Desktop**: Enhanced AI responses with domain knowledge
- **CLI Tools**: Command-line documentation search
- **API Gateway**: REST endpoints for custom integrations

### Enterprise Features
- **Multi-tenancy**: Isolated libraries per organization
- **Access Control**: Role-based permissions, audit logs
- **Analytics**: Usage tracking, search analytics
- **Compliance**: GDPR-ready, SOC2 compatible

### Research Applications
- **Academic Papers**: Encrypted research document analysis
- **Legal Documents**: Confidential case law research
- **Medical Records**: HIPAA-compliant document Q&A
- **Financial Reports**: Sensitive financial analysis

## üìã Po≈æiadavky

### Syst√©mov√© po≈æiadavky
- Python >= 3.10
- Ollama server be≈æiaci na `localhost:11434`
- Modely v Ollama: `mistral:latest` a `nomic-embed-text`

### Python z√°vislosti
```bash
pip install -r requirements.txt
```

```txt
memvid
pymupdf
requests
tqdm
tiktoken
```

## üèóÔ∏è Architekt√∫ra

### Core Components

#### 1. **OllamaEmbedder**
- **Purpose**: Generate embeddings using `nomic-embed-text` model
- **Endpoint**: `POST http://localhost:11434/api/generate`
- **Parameters**: `{"model": "nomic-embed-text", "embedding": true}`

#### 2. **PDFLibraryProcessor**
- **Basic processing** with standard chunking
- **Configuration**:
  - Input folder: `./pdf_books`
  - Output folder: `./memvid_out`
  - Chunk size: 512 characters, Overlap: 50 characters
  - Output: 8,975 segments, ~482 chars average

#### 3. **PDFLibraryProcessor (Enhanced with Token-Based Chunking)**
- **Advanced processing** with high-quality text extraction and intelligent chunking
- **PyMuPDF Integration**: Eliminates encoding issues that caused Issue #2 problems
- **Token-Based Sliding Window**: Consistent 500-token chunks with 15% overlap
- **Configuration**:
  - Input folder: `./pdf_books`
  - Output folder: `./memvid_out`
  - Chunk size: 500 tokens (~2000 characters)
  - Overlap: 75 tokens (15%)
  - Method: Sliding window with semantic boundary detection
  - Features: Cross-page chunks, detailed page references, automatic text cleaning

### Workflow

```mermaid
graph TD
    A[PDF s√∫bory] --> B[PyMuPDF extrakcia textu]
    B --> C[Text cleaning - Issue #2 fix]
    C --> D[Token-based chunking - 500 tokens]
    D --> E[Sliding window overlap - 15%]
    E --> F[Semantic boundary cleaning]
    F --> G[Prv√Ωch 10 chunks pre metadata]
    G --> H[Ollama mistral:latest]
    H --> I[JSON metad√°ta]
    I --> J[Memvid encoder]
    J --> K[QR frames generovanie]
    K --> L[Video + Index]
```

## üîß Funkcionalita

### 1. Extrakcia metad√°t pomocou AI

```python
def extract_metadata_with_ollama(self, sample_text: str) -> Dict[str, str]:
```

**Proces**:
1. Vezme prv√Ωch 10 chunks z PDF
2. Spoj√≠ ich do sample_text 
3. Po≈°le prompt do `mistral:latest`:
   ```
   Extract JSON with keys: title, authors, publishers, year, doi from this text:
   [sample_text]
   Return only valid JSON.
   ```
4. Parsuje JSON odpoveƒè
5. Validuje a normalizuje d√°ta

**V√Ωstup**:
```json
{
  "title": "RAG-Driven Generative AI",
  "authors": "Denis Rothman",
  "publishers": "Packt Publishing", 
  "year": "2024",
  "doi": "10.1234/example"
}
```

### 2. PDF Processing Pipeline

```python
def process_pdf(self, pdf_path: Path) -> bool:
```

**Kroky**:
1. **Extrakcia textu** pomocou PyPDF2
2. **Chunking** na ~100 slov per chunk
3. **Metadata extraction** z prv√Ωch 10 chunks
4. **Pridanie do memvid** encoder

### 3. Video Index Generation

```python
encoder.add_pdf(str(pdf_path), chunk_size=512, overlap=50)
encoder.build_video("library.mp4", "library_index.json")
```

**Vytvor√≠**:
- üé• **library.mp4**: Video kde ka≈æd√Ω frame obsahuje QR k√≥d s chunks
- üìã **library_index.json**: Metadata a mappings
- üîç **library_index.faiss**: Vector search index

## üìÅ Project Structure

```
eLibrary/
‚îú‚îÄ‚îÄ pdf_library_processor.py      # Enhanced PDF processor with page metadata
‚îú‚îÄ‚îÄ pdf_library_chat.py           # Interactive chat interface
‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies
‚îú‚îÄ‚îÄ README.md                     # This documentation
‚îú‚îÄ‚îÄ .gitignore                    # Git ignore rules
‚îú‚îÄ‚îÄ .github/                      # ü§ñ GitHub Actions automation
‚îÇ   ‚îú‚îÄ‚îÄ workflows/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auto-fix-issues.yml   # Automated issue fixing workflow
‚îÇ   ‚îú‚îÄ‚îÄ actions/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ claude-ai-fix/        # Custom AI fix action
‚îÇ   ‚îú‚îÄ‚îÄ ISSUE_TEMPLATE/           # Structured issue templates
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auto-fix-bug.md       # Bug report template
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auto-fix-enhancement.md # Enhancement template
‚îÇ   ‚îú‚îÄ‚îÄ README.md                 # GitHub Actions documentation
‚îÇ   ‚îú‚îÄ‚îÄ SETUP_INSTRUCTIONS.md     # Setup guide
‚îÇ   ‚îî‚îÄ‚îÄ test_auto_fix.py          # Test script
‚îú‚îÄ‚îÄ pdf_books/                    # Input PDF files (excluded from git)
‚îÇ   ‚îú‚îÄ‚îÄ book1.pdf
‚îÇ   ‚îî‚îÄ‚îÄ book2.pdf
‚îú‚îÄ‚îÄ memvid_out/                   # Output (excluded from git)
‚îÇ   ‚îú‚îÄ‚îÄ library.mp4              # Video index
‚îÇ   ‚îú‚îÄ‚îÄ library_index.json       # Enhanced metadata
‚îÇ   ‚îî‚îÄ‚îÄ library_index.faiss      # Vector index
‚îî‚îÄ‚îÄ venv/                        # Python virtual environment (excluded)
```

## üöÄ Pou≈æitie

### 1. Pr√≠prava prostredia

```bash
# Vytvorenie virtual environment
python3 -m venv venv
source venv/bin/activate

# In≈°tal√°cia z√°vislost√≠
pip install -r requirements.txt
```

### 2. Spustenie Ollama

```bash
# Stiahnutie modelov
ollama pull mistral:latest
ollama pull nomic-embed-text

# Overenie ≈æe Ollama be≈æ√≠
curl http://localhost:11434/api/tags
```

### 3. Pridanie PDF s√∫borov

```bash
# Vytvorenie prieƒçinka a pridanie PDF
mkdir -p pdf_books
cp *.pdf pdf_books/
```

### 4. Run Processing

**Main Processor**
```bash
python3 pdf_library_processor.py
```

```bash
python3 pdf_library_processor.py
```

**Benefits:**
- 61% more text segments (14,486 vs 8,975)
- Shorter, more precise chunks (362 vs 482 chars)
- Cross-page context preservation (2,184 cross-page chunks)
- Detailed page metadata for each chunk
- Enhanced statistics and book information

### 5. Chat s kni≈ænicou

Po vytvoren√≠ video indexu m√¥≈æete spusti≈• chat interface:

```bash
python3 pdf_library_chat.py
```

## üìä Processing Results

### Enhanced Output
```
Found 7 PDF files to process
Output directory: memvid_out_v2
Chunk size: 400 chars, Overlap: 50 chars

Processing: RAG-Driven Generative AI...
  - Pages: 517, Enhanced chunks: 2316
  - Extracting metadata...
  - Title: RAG-Driven Generative AI
  - Authors: Denis Rothman
  - Year: 2024

Generating QR frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14486/14486 [24:09<00:00]
Enhancing index with detailed metadata...

‚úÖ SUCCESS!
üìö Processed 7 PDF books
üé• Enhanced video: memvid_out/library.mp4
üìã Enhanced index: memvid_out/library_index.json
üìÑ Each chunk includes detailed page references!
```

### Performance Comparison

| Metric | Previous | Current | Improvement |
|--------|----------|-------------|-------------|
| Total segments | 8,975 | 14,486 | +61% |
| Avg segment length | 482 chars | 362 chars | -25% (more precise) |
| Cross-page chunks | 0 | 2,184 | New feature |
| Page metadata | Basic | Detailed | Enhanced |
| Unique pages indexed | N/A | 2,245 | New feature |

### Vytvoren√© s√∫bory

#### `library.mp4`
- Video kde ka≈æd√Ω frame = 1 chunk ako QR k√≥d
- Framerate: 1 FPS (default memvid)
- Form√°t: MP4 s H.264 codec

#### `library_index.json` (Enhanced)
```json
{
  "metadata": [
    {
      "id": 0,
      "text": "RAG-Driven Generative AI\nBuild custom retrieval...",
      "frame": 0,
      "length": 134
    }
  ],
  "enhanced_stats": {
    "total_files": 7,
    "total_chunks": 14486,
    "total_unique_pages": 2245,
    "cross_page_chunks": 2184,
    "files": {
      "RAG-Driven Generative AI...pdf": {
        "chunks": 2316,
        "unique_pages": 517,
        "title": "RAG-Driven Generative AI",
        "authors": "Denis Rothman",
        "year": "2024"
      }
    }
  }
}
```

#### `library_index.faiss`
- Bin√°rny FAISS vector index
- 384-dimenzion√°lne embeddings (nomic-embed-text)
- Umo≈æ≈àuje semantick√© vyhƒæad√°vanie

## üîç Intern√© detaily

### Chunk Storage Lifecycle

1. **V pam√§ti**: `encoder.chunks[]` - list v≈°etk√Ωch chunks
2. **Doƒçasne**: `/tmp/tmp*/frames/frame_*.png` - QR obr√°zky
3. **Fin√°lne**: `library.mp4` + index s√∫bory

### Error Handling

```python
# PDF parsing errors
except Exception as e:
    print(f"Error reading PDF {pdf_path}: {e}")
    return [], 0

# Ollama API errors  
except Exception as e:
    print(f"Error extracting metadata with Ollama: {e}")
    return self._empty_metadata()
```

### Performance

- **Chunk generovanie**: ~10 chunks/sec
- **QR frame generovanie**: ~10-15 frames/sec  
- **Metadata extrakcia**: ~5-10 sec per PDF
- **Celkov√Ω ƒças**: ~2-3 min pre 7 PDF (varies by size)

## üéõÔ∏è Konfigur√°cia

### Memvid parametre
```python
# V PDFLibraryProcessor.__init__()
self.encoder = MemvidEncoder()

# V process_pdf()
self.encoder.add_pdf(str(pdf_path), chunk_size=512, overlap=50)
```

### Ollama endpointy
```python
# Embeddings
POST http://localhost:11434/api/generate
{
  "model": "nomic-embed-text",
  "prompt": text,
  "embedding": true
}

# Metadata extraction
POST http://localhost:11434/api/generate  
{
  "model": "mistral:latest",
  "prompt": "Extract JSON...",
  "options": {"temperature": 0.1}
}
```

## ‚ö†Ô∏è Zn√°me limit√°cie

1. **PDF parsing**: Niektor√© PDF m√¥≈æu ma≈• probl√©my s text extraction
2. **Ollama dostupnos≈•**: Vy≈æaduje be≈æiaci Ollama server
3. **Memory usage**: Veƒæk√© PDF m√¥≈æu spotrebova≈• veƒæa RAM
4. **Processing time**: Video generovanie je ƒçasovo n√°roƒçn√©
5. **Metadata quality**: Z√°vis√≠ od kvality text extraction a AI modelu

## üîß Troubleshooting

### Ollama connection failed
```bash
# Skontrolova≈• ƒçi Ollama be≈æ√≠
ollama list
curl http://localhost:11434/api/tags
```

### PDF extraction errors
```python
# Skontrolova≈• PyPDF2 log v konzole
# Niektor√© PDF m√¥≈æu by≈• chr√°nen√©/po≈°koden√©
```

### Memory errors
```bash
# Spracov√°va≈• PDF po men≈°√≠ch d√°vkach
# Alebo zv√Ω≈°i≈• system memory/swap
```

## ü§ñ GitHub Actions Automatiz√°cia

‚úÖ **Kompletne implementovan√Ω automatizovan√Ω syst√©m na rie≈°enie issues!**

### üéØ Ako pou≈æ√≠va≈•:

#### 1. **Vytvorte issue s template:**
```
GitHub ‚Üí Issues ‚Üí New issue ‚Üí Choose template:
- ü§ñ Auto-Fix Bug Report
- üöÄ Auto-Fix Enhancement
```

#### 2. **Aktivujte automatiz√°ciu:**
```bash
# Pridajte label na issue
gh issue edit ISSUE_NUMBER --add-label "auto-fix"

# Alebo cez web interface v GitHub
```

#### 3. **Sledujte progress:**
```bash
# GitHub Actions workflow sa automaticky spust√≠
https://github.com/entira/elibrary/actions

# AI vytvor√≠ PR s rie≈°en√≠m
gh pr list --label "auto-fix"
```

### üõ†Ô∏è Implementovan√© komponenty:
- ‚úÖ **GitHub Actions workflow** (`.github/workflows/auto-fix-issues.yml`)
- ‚úÖ **Issue templates** s ≈°trukt√∫rovan√Ωm formul√°rom
- ‚úÖ **Custom AI action** pre automated fixes
- ‚úÖ **Automated testing** a validation
- ‚úÖ **Smart labeling system**

### üìã Ako to funguje:
1. **Issue detection** - workflow reaguje na label `auto-fix`
2. **AI analysis** - analyzuje probl√©m a k√≥d context
3. **Fix generation** - vytvor√≠ rie≈°enie based on issue description
4. **Automated testing** - validuje syntax a imports
5. **PR creation** - vytvor√≠ pull request s fix
6. **Manual review** - vy≈æaduje human approval pred merge

### üìö Dokument√°cia:
- **Setup guide**: [`.github/SETUP_INSTRUCTIONS.md`](.github/SETUP_INSTRUCTIONS.md)
- **System overview**: [`.github/README.md`](.github/README.md)
- **Test script**: [`.github/test_auto_fix.py`](.github/test_auto_fix.py)

## üìà Roz≈°√≠renia

### Mo≈æn√© vylep≈°enia
1. **Batch processing**: Spracovanie po d√°vkach pre veƒæk√© kolekcie
2. **Multi-threading**: Paraleln√© spracovanie PDF
3. **Database storage**: Ukladanie do DB namiesto JSON
4. **Web interface**: GUI pre browsing a vyhƒæad√°vanie
5. **Alternative models**: Podpora pre in√© LLM/embedding modely

### Custom metadata fields
```python
# Prida≈• nov√© pole do metadata extraction prompt
prompt = f"""Extract JSON with keys: title, authors, publishers, year, doi, isbn, language from this text:
{sample_text}
Return only valid JSON."""
```

# PDF Library Chat Interface

Interactive chat system for communicating with PDF library using video memory.

## üéØ Functionality

### Chat Commands
```
help          - Show help message
info          - Library information  
search <query>- Search library content
stats         - Session statistics
clear         - Clear screen
exit/quit     - Exit chat
```

### Usage Examples

```bash
ü§î You: How to make better podcasts?
ü§ñ Assistant: To make better podcasts, you should:

1. Balance speed and quality. [Podcasting 100 Success Secrets, page 54]
2. Limit the podcast to a short running time. [Podcasting For Dummies, page 27]
3. Use proper microphone technique. [Podcasting 100 Success Secrets, page 140]

‚è±Ô∏è Response time: 3.45s

üîç DEBUG - Full prompt used:
============================================================
[Complete prompt with context and citations shown here]
============================================================

ü§î You: search machine learning
üîç Search results for: 'machine learning' (0.15s)
üìÑ Relevant passages:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
[Relevant text chunks from PDFs with citations...]
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

ü§î You: info
üìñ Library Overview:
   üìö Total books: 7
   üìù Total chunks: 5109

üìë Books in library:
   1. RAG-Driven Generative AI
      üìñ Author(s): Denis Rothman
      üè¢ Publisher(s): Packt Publishing
      üìÖ Year: 2024
      üîó DOI/ISBN: 978-1-83620-091-8
      üìÑ Pages: 517
      üìù Chunks: 1022
```

## üéØ New Citation Features

### Enhanced Chat Responses
- **Source Citations**: Every response includes specific book titles and page numbers
- **Accurate Page References**: Uses real PDF page numbers for easy verification
- **Debug Mode**: Full prompt and context shown after each response
- **Citation Format**: `[Book Title, page X]` at end of sentences

### Enhanced Library Display
- **Complete Metadata**: Shows authors, publishers, year, DOI/ISBN
- **Full Titles**: No truncation of book titles or author names
- **Organized Layout**: Pages listed before chunks for better readability

## üîß Technical Details

### Components
- **PDFLibraryChat**: Main chat interface class
- **OllamaLLM**: Local LLM for response generation  
- **MemvidChat/MemvidRetriever**: Video memory search and retrieval
- **Citation Engine**: Matches search results with enhanced metadata

### Workflow
1. **Load video index** and validate files
2. **Semantic search** in PDF chunks using embeddings
3. **Context retrieval** with metadata matching
4. **Citation addition** using enhanced_metadata from index
5. **LLM response** using Ollama mistral:latest with citation instructions
6. **Formatted output** with source citations and debug information

### Configuration
```python
# Enhanced initialization
self.chat = MemvidChat(video_file, index_file, llm_provider=None)
self.llm = OllamaLLM(model="mistral:latest")

# Citation prompt format
INSTRUCTIONS:
- Put citations at the END of sentences, not in the middle
- Use format: [Book Title, page X]
- Example: "Balance speed with quality. [Podcasting 100 Success Secrets, page 54]"
```

## üìù Version History

### Current - Enhanced Processing
- **14,486 segments** with detailed page metadata
- **Cross-page chunks** for better context preservation
- **Enhanced statistics** and book information
- **Improved chunking** (400 chars vs 512 chars)
- **Better RAG performance** with more precise segments

### Previous - Basic Processing
- **8,975 segments** with basic metadata
- **512-character chunks** with standard overlap
- **Simple PDF processing** without page references

---

**Repository**: eLibrary PDF Knowledge Base  
**Version**: 2.0 Enhanced  
**Last Updated**: December 2024  
**License**: MIT